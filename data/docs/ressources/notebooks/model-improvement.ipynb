{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# Challenge d'amélioration de modèle CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"## BTS SIO  - Séance 2: Types de réseaux et applications\\n\",\n",
    "        \"\\n\",\n",
    "        \"Ce notebook vous guidera à travers un challenge d'amélioration d'un modèle CNN pour la classification d'images de vêtements (Fashion MNIST). Vous partirez d'un modèle de base volontairement sous-optimal et explorerez différentes stratégies pour améliorer ses performances.\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Objectifs d'apprentissage:\\n\",\n",
    "        \"- Diagnostiquer les faiblesses d'un modèle de Deep Learning\\n\",\n",
    "        \"- Expérimenter avec différentes architectures et hyperparamètres\\n\",\n",
    "        \"- Appliquer des techniques d'optimisation (dropout, batch normalization, etc.)\\n\",\n",
    "        \"- Mesurer et comparer quantitativement les améliorations\\n\",\n",
    "        \"- Documenter méthodiquement les modifications et leurs impacts\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Prérequis:\\n\",\n",
    "        \"- Connaissances de base en TensorFlow/Keras\\n\",\n",
    "        \"- Compréhension des principes des réseaux CNN\\n\",\n",
    "        \"- Avoir suivi la première partie du TP sur les CNN\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 1. Configuration de l'environnement\\n\",\n",
    "        \"\\n\",\n",
    "        \"Commençons par importer les bibliothèques nécessaires.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tensorflow.keras.models import Sequential, load_model\\n\",\n",
    "        \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\\n\",\n",
    "        \"from tensorflow.keras.optimizers import Adam, RMSprop, SGD\\n\",\n",
    "        \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
    "        \"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\\n\",\n",
    "        \"from tensorflow.keras.datasets import fashion_mnist\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import time\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"import seaborn as sns\\n\",\n",
    "        \"from sklearn.metrics import confusion_matrix\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Configuration pour reproductibilité\\n\",\n",
    "        \"np.random.seed(42)\\n\",\n",
    "        \"tf.random.set_seed(42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Vérifier la version de TensorFlow\\n\",\n",
    "        \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 2. Chargement du dataset Fashion MNIST\\n\",\n",
    "        \"\\n\",\n",
    "        \"Fashion MNIST est un dataset similaire au MNIST original, mais avec des images de vêtements au lieu de chiffres. C'est un excellent dataset pour tester des modèles de vision par ordinateur.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"Chargement du dataset Fashion MNIST...\\\")\\n\",\n",
    "        \"(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Normalisation et reshape pour correspondre au format attendu par le CNN\\n\",\n",
    "        \"x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Noms des classes pour l'affichage\\n\",\n",
    "        \"class_names = ['T-shirt/top', 'Pantalon', 'Pull', 'Robe', 'Manteau',\\n\",\n",
    "        \"               'Sandale', 'Chemise', 'Basket', 'Sac', 'Bottine']\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"Forme des données d'entraînement: {x_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Forme des données de test: {x_test.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Nombre de classes: {len(class_names)}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation de quelques exemples\\n\",\n",
    "        \"\\n\",\n",
    "        \"Examinons à quoi ressemblent les images de notre dataset.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(10, 10))\\n\",\n",
    "        \"for i in range(25):\\n\",\n",
    "        \"    plt.subplot(5, 5, i+1)\\n\",\n",
    "        \"    plt.xticks([])\\n\",\n",
    "        \"    plt.yticks([])\\n\",\n",
    "        \"    plt.grid(False)\\n\",\n",
    "        \"    plt.imshow(x_train[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.xlabel(class_names[y_train[i]])\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 3. Tableau de bord des résultats\\n\",\n",
    "        \"\\n\",\n",
    "        \"Créons une classe pour suivre et comparer les performances des différents modèles que nous allons tester.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"class ModelImprovementDashboard:\\n\",\n",
    "        \"    \\\"\\\"\\\"Classe pour suivre et afficher les résultats des différentes améliorations\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def __init__(self):\\n\",\n",
    "        \"        self.results = []\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def add_result(self, model_name, metrics, notes=\\\"\\\"):\\n\",\n",
    "        \"        \\\"\\\"\\\"Ajoute un résultat au tableau de bord\\\"\\\"\\\"\\n\",\n",
    "        \"        result = {\\n\",\n",
    "        \"            'model_name': model_name,\\n\",\n",
    "        \"            'accuracy': metrics['test_accuracy'],\\n\",\n",
    "        \"            'loss': metrics['test_loss'],\\n\",\n",
    "        \"            'training_time': metrics['training_time'],\\n\",\n",
    "        \"            'epochs': metrics['epochs_completed'],\\n\",\n",
    "        \"            'notes': notes\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"        self.results.append(result)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def show_results(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"Affiche un tableau comparatif des résultats\\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.results:\\n\",\n",
    "        \"            print(\\\"Aucun résultat à afficher.\\\")\\n\",\n",
    "        \"            return\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Créer un DataFrame\\n\",\n",
    "        \"        df = pd.DataFrame(self.results)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Trier par précision (descendant)\\n\",\n",
    "        \"        df = df.sort_values(by='accuracy', ascending=False)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Formater les colonnes\\n\",\n",
    "        \"        df['accuracy'] = df['accuracy'].apply(lambda x: f\\\"{x:.2f}%\\\")\\n\",\n",
    "        \"        df['loss'] = df['loss'].apply(lambda x: f\\\"{x:.4f}\\\")\\n\",\n",
    "        \"        df['training_time'] = df['training_time'].apply(lambda x: f\\\"{x:.2f}s\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        print(\\\"\\\\n=== TABLEAU COMPARATIF DES MODÈLES ===\\\")\\n\",\n",
    "        \"        print(df)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        return df\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def plot_comparison(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"Visualise la comparaison des modèles\\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.results:\\n\",\n",
    "        \"            print(\\\"Aucun résultat à afficher.\\\")\\n\",\n",
    "        \"            return\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Préparer les données\\n\",\n",
    "        \"        models = [r['model_name'] for r in self.results]\\n\",\n",
    "        \"        accuracies = [float(r['accuracy'].strip('%')) for r in self.results]\\n\",\n",
    "        \"        times = [float(r['training_time'].strip('s')) for r in self.results]\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Créer le graphique\\n\",\n",
    "        \"        plt.figure(figsize=(12, 6))\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Graphique de précision\\n\",\n",
    "        \"        plt.subplot(1, 2, 1)\\n\",\n",
    "        \"        bars = plt.bar(models, accuracies, color='skyblue')\\n\",\n",
    "        \"        plt.title('Comparaison des précisions')\\n\",\n",
    "        \"        plt.xlabel('Modèle')\\n\",\n",
    "        \"        plt.ylabel('Précision (%)')\\n\",\n",
    "        \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Ajouter les valeurs sur les barres\\n\",\n",
    "        \"        for bar in bars:\\n\",\n",
    "        \"            height = bar.get_height()\\n\",\n",
    "        \"            plt.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "        \"                     f'{height:.2f}%',\\n\",\n",
    "        \"                     ha='center', va='bottom')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Graphique de temps d'entraînement\\n\",\n",
    "        \"        plt.subplot(1, 2, 2)\\n\",\n",
    "        \"        bars = plt.bar(models, times, color='salmon')\\n\",\n",
    "        \"        plt.title('Comparaison des temps d\\\\'entraînement')\\n\",\n",
    "        \"        plt.xlabel('Modèle')\\n\",\n",
    "        \"        plt.ylabel('Temps (secondes)')\\n\",\n",
    "        \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Ajouter les valeurs sur les barres\\n\",\n",
    "        \"        for bar in bars:\\n\",\n",
    "        \"            height = bar.get_height()\\n\",\n",
    "        \"            plt.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "        \"                     f'{height:.2f}s',\\n\",\n",
    "        \"                     ha='center', va='bottom')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        plt.tight_layout()\\n\",\n",
    "        \"        plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Initialiser le tableau de bord\\n\",\n",
    "        \"dashboard = ModelImprovementDashboard()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 4. Fonctions d'évaluation de modèle\\n\",\n",
    "        \"\\n\",\n",
    "        \"Définissons des fonctions pour entraîner, évaluer et visualiser les modèles de manière cohérente.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def evaluate_model(model, x_train, y_train, x_test, y_test, epochs=5, batch_size=128, data_augmentation=False):\\n\",\n",
    "        \"    \\\"\\\"\\\"Entraîne et évalue un modèle, retourne les métriques de performance\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Configuration pour l'augmentation de données (si activée)\\n\",\n",
    "        \"    if data_augmentation:\\n\",\n",
    "        \"        train_datagen = ImageDataGenerator(\\n\",\n",
    "        \"            rotation_range=10,\\n\",\n",
    "        \"            width_shift_range=0.1,\\n\",\n",
    "        \"            height_shift_range=0.1,\\n\",\n",
    "        \"            zoom_range=0.1,\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"        train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Callbacks pour améliorer l'entraînement\\n\",\n",
    "        \"    callbacks = []\\n\",\n",
    "        \"    if epochs > 5:\\n\",\n",
    "        \"        callbacks = [\\n\",\n",
    "        \"            EarlyStopping(patience=5, restore_best_weights=True),\\n\",\n",
    "        \"            ReduceLROnPlateau(factor=0.2, patience=3, min_lr=0.0001)\\n\",\n",
    "        \"        ]\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Mesure du temps d'entraînement\\n\",\n",
    "        \"    start_time = time.time()\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Entraînement du modèle\\n\",\n",
    "        \"    if data_augmentation:\\n\",\n",
    "        \"        history = model.fit(\\n\",\n",
    "        \"            train_generator,\\n\",\n",
    "        \"            epochs=epochs,\\n\",\n",
    "        \"            steps_per_epoch=len(x_train) // batch_size,\\n\",\n",
    "        \"            validation_data=(x_test, y_test),\\n\",\n",
    "        \"            callbacks=callbacks,\\n\",\n",
    "        \"            verbose=1\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        history = model.fit(\\n\",\n",
    "        \"            x_train, y_train,\\n\",\n",
    "        \"            batch_size=batch_size,\\n\",\n",
    "        \"            epochs=epochs,\\n\",\n",
    "        \"            validation_data=(x_test, y_test),\\n\",\n",
    "        \"            callbacks=callbacks,\\n\",\n",
    "        \"            verbose=1\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    training_time = time.time() - start_time\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Évaluation du modèle\\n\",\n",
    "        \"    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Préparer les métriques\\n\",\n",
    "        \"    metrics = {\\n\",\n",
    "        \"        'test_accuracy': test_acc * 100,\\n\",\n",
    "        \"        'test_loss': test_loss,\\n\",\n",
    "        \"        'training_time': training_time,\\n\",\n",
    "        \"        'epochs_completed': len(history.history['loss']),\\n\",\n",
    "        \"        'history': history\\n\",\n",
    "        \"    }\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return metrics\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_training_history(history):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise l'historique d'entraînement\\\"\\\"\\\"\\n\",\n",
    "        \"    plt.figure(figsize=(12, 5))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Graphique de précision\\n\",\n",
    "        \"    plt.subplot(1, 2, 1)\\n\",\n",
    "        \"    plt.plot(history.history['accuracy'], label='Entraînement')\\n\",\n",
    "        \"    plt.plot(history.history['val_accuracy'], label='Validation')\\n\",\n",
    "        \"    plt.title('Évolution de la précision')\\n\",\n",
    "        \"    plt.xlabel('Époque')\\n\",\n",
    "        \"    plt.ylabel('Précision')\\n\",\n",
    "        \"    plt.legend()\\n\",\n",
    "        \"    plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Graphique de perte\\n\",\n",
    "        \"    plt.subplot(1, 2, 2)\\n\",\n",
    "        \"    plt.plot(history.history['loss'], label='Entraînement')\\n\",\n",
    "        \"    plt.plot(history.history['val_loss'], label='Validation')\\n\",\n",
    "        \"    plt.title('Évolution de la perte')\\n\",\n",
    "        \"    plt.xlabel('Époque')\\n\",\n",
    "        \"    plt.ylabel('Perte')\\n\",\n",
    "        \"    plt.legend()\\n\",\n",
    "        \"    plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_confusion_matrix(model, x_test, y_test):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise la matrice de confusion du modèle\\\"\\\"\\\"\\n\",\n",
    "        \"    # Prédictions\\n\",\n",
    "        \"    y_pred = model.predict(x_test)\\n\",\n",
    "        \"    y_pred_classes = np.argmax(y_pred, axis=1)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Calculer la matrice de confusion\\n\",\n",
    "        \"    conf_mat = confusion_matrix(y_test, y_pred_classes)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Visualisation\\n\",\n",
    "        \"    plt.figure(figsize=(10, 8))\\n\",\n",
    "        \"    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\\n\",\n",
    "        \"                xticklabels=class_names,\\n\",\n",
    "        \"                yticklabels=class_names)\\n\",\n",
    "        \"    plt.xlabel('Prédit')\\n\",\n",
    "        \"    plt.ylabel('Réel')\\n\",\n",
    "        \"    plt.title('Matrice de confusion')\\n\",\n",
    "        \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"def show_misclassified_examples(model, x_test, y_test, n=10):\\n\",\n",
    "        \"    \\\"\\\"\\\"Affiche des exemples d'images mal classifiées\\\"\\\"\\\"\\n\",\n",
    "        \"    predictions = model.predict(x_test)\\n\",\n",
    "        \"    predicted_classes = np.argmax(predictions, axis=1)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Trouver les erreurs\\n\",\n",
    "        \"    errors = (predicted_classes != y_test)\\n\",\n",
    "        \"    error_indices = np.where(errors)[0]\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    if len(error_indices) == 0:\\n\",\n",
    "        \"        print(\\\"Aucune erreur trouvée!\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Sélectionner un échantillon d'erreurs\\n\",\n",
    "        \"    sample_size = min(n, len(error_indices))\\n\",\n",
    "        \"    sample_indices = np.random.choice(error_indices, size=sample_size, replace=False)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les exemples\\n\",\n",
    "        \"    plt.figure(figsize=(15, 3*sample_size//5 + 3))\\n\",\n",
    "        \"    for i, idx in enumerate(sample_indices):\\n\",\n",
    "        \"        plt.subplot(sample_size//5 + 1, 5, i+1)\\n\",\n",
    "        \"        plt.imshow(x_test[idx].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"        plt.title(f\\\"Réel: {class_names[y_test[idx]]}\\\\nPrédit: {class_names[predicted_classes[idx]]}\\\")\\n\",\n",
    "        \"        plt.axis('off')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 5. Modèle de base (sous-optimal)\\n\",\n",
    "        \"\\n\",\n",
    "        \"Commençons par créer et évaluer un modèle CNN de base, volontairement sous-optimal, qui servira de point de référence pour nos améliorations.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_baseline_model():\\n\",\n",
    "        \"    \\\"\\\"\\\"Crée un modèle CNN de base volontairement sous-performant\\\"\\\"\\\"\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        Flatten(),\\n\",\n",
    "        \"        Dense(16, activation='relu'),\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer=Adam(learning_rate=0.01),  # Learning rate trop élevé\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Créer et afficher le modèle de base\\n\",\n",
    "        \"baseline_model = create_baseline_model()\\n\",\n",
    "        \"baseline_model.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Entraînement et évaluation du modèle de base\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"\\\\n--- Modèle de base ---\\\")\\n\",\n",
    "        \"baseline_metrics = evaluate_model(baseline_model, x_train, y_train, x_test, y_test, epochs=5)\\n\",\n",
    "        \"print(f\\\"Précision du modèle de base: {baseline_metrics['test_accuracy']:.2f}%\\\")\\n\",\n",
    "        \"print(f\\\"Temps d'entraînement: {baseline_metrics['training_time']:.2f} secondes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser l'historique d'entraînement\\n\",\n",
    "        \"plot_training_history(baseline_metrics['history'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Ajouter au tableau de bord\\n\",\n",
    "        \"dashboard.add_result(\\\"Modèle de base\\\", baseline_metrics, \\n\",\n",
    "        \"                     \\\"CNN simple, peu de filtres, learning rate élevé\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Analyse des erreurs du modèle de base\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Afficher la matrice de confusion\\n\",\n",
    "        \"plot_confusion_matrix(baseline_model, x_test, y_test)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher des exemples d'erreurs\\n\",\n",
    "        \"print(\\\"\\\\nExemples d'erreurs de classification du modèle de base:\\\")\\n\",\n",
    "        \"show_misclassified_examples(baseline_model, x_test, y_test)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### 🔍 Diagnostic du modèle de base\\n\",\n",
    "        \"\\n\",\n",
    "        \"Avant de passer aux améliorations, analysons les problèmes du modèle de base :\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. **Architecture trop simple** : \\n\",\n",
    "        \"   - Seulement 8 filtres dans la couche de convolution\\n\",\n",
    "        \"   - Une seule couche de convolution\\n\",\n",
    "        \"   - Seulement 16 neurones dans la couche dense\\n\",\n",
    "        \"   \\n\",\n",
    "        \"2. **Optimisation problématique** :\\n\",\n",
    "        \"   - Taux d'apprentissage trop élevé (0.01)\\n\",\n",
    "        \"   - Pas de régularisation (dropout, etc.)\\n\",\n",
    "        \"   - Nombre d'époques potentiellement insuffisant\\n\",\n",
    "        \"   \\n\",\n",
    "        \"3. **Prétraitement minimal** :\\n\",\n",
    "        \"   - Pas d'augmentation de données\\n\",\n",
    "        \"   - Pas de normalisation batch\\n\",\n",
    "        \"\\n\",\n",
    "        \"Ces observations nous guideront dans nos tentatives d'amélioration.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 6. Première amélioration : Architecture plus profonde\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour notre première amélioration, nous allons :\\n\",\n",
    "        \"- Augmenter le nombre de filtres\\n\",\n",
    "        \"- Ajouter une couche de convolution supplémentaire\\n\",\n",
    "        \"- Augmenter le nombre de neurones dans la couche dense\\n\",\n",
    "        \"- Réduire le taux d'apprentissage\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_improved_model_1():\\n\",\n",
    "        \"    \\\"\\\"\\\"Premier exemple d'amélioration: architecture plus profonde\\\"\\\"\\\"\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        Flatten(),\\n\",\n",
    "        \"        Dense(128, activation='relu'),\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer=Adam(learning_rate=0.001),  # Taux d'apprentissage réduit\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Créer et afficher le modèle amélioré 1\\n\",\n",
    "        \"improved_model_1 = create_improved_model_1()\\n\",\n",
    "        \"improved_model_1.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Entraînement et évaluation du modèle amélioré 1\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"\\\\n--- Modèle amélioré 1 ---\\\")\\n\",\n",
    "        \"improved_metrics_1 = evaluate_model(improved_model_1, x_train, y_train, x_test, y_test, epochs=10)\\n\",\n",
    "        \"print(f\\\"Précision du modèle amélioré 1: {improved_metrics_1['test_accuracy']:.2f}%\\\")\\n\",\n",
    "        \"print(f\\\"Temps d'entraînement: {improved_metrics_1['training_time']:.2f} secondes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser l'historique d'entraînement\\n\",\n",
    "        \"plot_training_history(improved_metrics_1['history'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Ajouter au tableau de bord\\n\",\n",
    "        \"dashboard.add_result(\\\"Modèle amélioré 1\\\", improved_metrics_1, \\n\",\n",
    "        \"                    \\\"Plus de filtres, couche supplémentaire, learning rate plus bas\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Analyse des résultats du modèle amélioré 1\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Visualiser les résultats de l'amélioration\\n\",\n",
    "        \"print(\\\"Comparaison des modèles jusqu'à présent:\\\")\\n\",\n",
    "        \"dashboard.show_results()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Voir les nouvelles erreurs\\n\",\n",
    "        \"print(\\\"\\\\nExemples d'erreurs après la première amélioration:\\\")\\n\",\n",
    "        \"show_misclassified_examples(improved_model_1, x_test, y_test)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 7. Deuxième amélioration : Régularisation et augmentation de données\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour notre deuxième amélioration, nous allons :\\n\",\n",
    "        \"- Ajouter du dropout pour éviter le surapprentissage\\n\",\n",
    "        \"- Intégrer la normalisation par batch (batch normalization)\\n\",\n",
    "        \"- Utiliser l'augmentation de données pour améliorer la généralisation\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Architecture du modèle amélioré 2\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_improved_model_2():\\n\",\n",
    "        \"    \\\"\\\"\\\"Deuxième exemple d'amélioration: ajout de dropout et batch normalization\\\"\\\"\\\"\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        # Première couche de convolution avec batch normalization\\n\",\n",
    "        \"        Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\\n\",\n",
    "        \"        BatchNormalization(),\\n\",\n",
    "        \"        Activation('relu'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Deuxième couche de convolution avec batch normalization\\n\",\n",
    "        \"        Conv2D(64, (3, 3), padding='same'),\\n\",\n",
    "        \"        BatchNormalization(),\\n\",\n",
    "        \"        Activation('relu'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Aplatissement\\n\",\n",
    "        \"        Flatten(),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couche dense avec batch normalization et dropout\\n\",\n",
    "        \"        Dense(128),\\n\",\n",
    "        \"        BatchNormalization(),\\n\",\n",
    "        \"        Activation('relu'),\\n\",\n",
    "        \"        Dropout(0.5),  # 50% de dropout pour la régularisation\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couche de sortie\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer=Adam(learning_rate=0.001),\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Créer et afficher le modèle amélioré 2\\n\",\n",
    "        \"improved_model_2 = create_improved_model_2()\\n\",\n",
    "        \"improved_model_2.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Entraînement avec augmentation de données\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour cette amélioration, nous allons également utiliser l'augmentation de données qui permet de générer artificiellement plus d'exemples d'entraînement en appliquant des transformations aux images existantes. Cela améliore la robustesse du modèle face aux variations qu'il pourrait rencontrer en conditions réelles.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"\\\\n--- Modèle amélioré 2 (avec augmentation de données) ---\\\")\\n\",\n",
    "        \"improved_metrics_2 = evaluate_model(improved_model_2, x_train, y_train, x_test, y_test, \\n\",\n",
    "        \"                                   epochs=15, data_augmentation=True)\\n\",\n",
    "        \"print(f\\\"Précision du modèle amélioré 2: {improved_metrics_2['test_accuracy']:.2f}%\\\")\\n\",\n",
    "        \"print(f\\\"Temps d'entraînement: {improved_metrics_2['training_time']:.2f} secondes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser l'historique d'entraînement\\n\",\n",
    "        \"plot_training_history(improved_metrics_2['history'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Ajouter au tableau de bord\\n\",\n",
    "        \"dashboard.add_result(\\\"Modèle amélioré 2\\\", improved_metrics_2, \\n\",\n",
    "        \"                    \\\"Dropout, BatchNorm, augmentation de données\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Analyse des résultats du modèle amélioré 2\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Visualiser la matrice de confusion\\n\",\n",
    "        \"plot_confusion_matrix(improved_model_2, x_test, y_test)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher des exemples d'erreurs\\n\",\n",
    "        \"print(\\\"\\\\nExemples d'erreurs après la deuxième amélioration:\\\")\\n\",\n",
    "        \"show_misclassified_examples(improved_model_2, x_test, y_test)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Comparer tous les modèles\\n\",\n",
    "        \"dashboard.show_results()\\n\",\n",
    "        \"dashboard.plot_comparison()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 8. Création de votre propre modèle amélioré\\n\",\n",
    "        \"\\n\",\n",
    "        \"C'est maintenant à vous de concevoir votre propre amélioration! Vous pouvez explorer différentes architectures, techniques d'optimisation, ou combinaisons d'approches.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Voici quelques pistes d'amélioration possibles:\\n\",\n",
    "        \"- Essayer différentes architectures (plus/moins de couches, filtres, etc.)\\n\",\n",
    "        \"- Expérimenter avec d'autres optimiseurs (RMSprop, SGD avec momentum, etc.)\\n\",\n",
    "        \"- Tester différentes techniques de régularisation\\n\",\n",
    "        \"- Modifier les paramètres d'augmentation de données\\n\",\n",
    "        \"- Utiliser des connexions résiduelles (comme dans les architectures ResNet)\\n\",\n",
    "        \"- Combiner les meilleures pratiques des modèles précédents\"\n",
    "      ]\n",
    "    },\n",
    ".\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couche de sortie\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Compilation\\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer='adam',  # Modifiez selon vos préférences\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Si vous êtes prêt à tester votre modèle, décommentez les lignes suivantes\\n\",\n",
    "        \"#your_model = create_your_improved_model()\\n\",\n",
    "        \"#your_model.summary()\"\n",
    "      ]\n",
    "    },\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
