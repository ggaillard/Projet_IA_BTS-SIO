{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# Challenge d'am√©lioration de mod√®le CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"## BTS SIO  - S√©ance 2: Types de r√©seaux et applications\\n\",\n",
    "        \"\\n\",\n",
    "        \"Ce notebook vous guidera √† travers un challenge d'am√©lioration d'un mod√®le CNN pour la classification d'images de v√™tements (Fashion MNIST). Vous partirez d'un mod√®le de base volontairement sous-optimal et explorerez diff√©rentes strat√©gies pour am√©liorer ses performances.\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Objectifs d'apprentissage:\\n\",\n",
    "        \"- Diagnostiquer les faiblesses d'un mod√®le de Deep Learning\\n\",\n",
    "        \"- Exp√©rimenter avec diff√©rentes architectures et hyperparam√®tres\\n\",\n",
    "        \"- Appliquer des techniques d'optimisation (dropout, batch normalization, etc.)\\n\",\n",
    "        \"- Mesurer et comparer quantitativement les am√©liorations\\n\",\n",
    "        \"- Documenter m√©thodiquement les modifications et leurs impacts\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Pr√©requis:\\n\",\n",
    "        \"- Connaissances de base en TensorFlow/Keras\\n\",\n",
    "        \"- Compr√©hension des principes des r√©seaux CNN\\n\",\n",
    "        \"- Avoir suivi la premi√®re partie du TP sur les CNN\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 1. Configuration de l'environnement\\n\",\n",
    "        \"\\n\",\n",
    "        \"Commen√ßons par importer les biblioth√®ques n√©cessaires.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tensorflow.keras.models import Sequential, load_model\\n\",\n",
    "        \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\\n\",\n",
    "        \"from tensorflow.keras.optimizers import Adam, RMSprop, SGD\\n\",\n",
    "        \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
    "        \"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\\n\",\n",
    "        \"from tensorflow.keras.datasets import fashion_mnist\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import time\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"import seaborn as sns\\n\",\n",
    "        \"from sklearn.metrics import confusion_matrix\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Configuration pour reproductibilit√©\\n\",\n",
    "        \"np.random.seed(42)\\n\",\n",
    "        \"tf.random.set_seed(42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# V√©rifier la version de TensorFlow\\n\",\n",
    "        \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 2. Chargement du dataset Fashion MNIST\\n\",\n",
    "        \"\\n\",\n",
    "        \"Fashion MNIST est un dataset similaire au MNIST original, mais avec des images de v√™tements au lieu de chiffres. C'est un excellent dataset pour tester des mod√®les de vision par ordinateur.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"Chargement du dataset Fashion MNIST...\\\")\\n\",\n",
    "        \"(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Normalisation et reshape pour correspondre au format attendu par le CNN\\n\",\n",
    "        \"x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Noms des classes pour l'affichage\\n\",\n",
    "        \"class_names = ['T-shirt/top', 'Pantalon', 'Pull', 'Robe', 'Manteau',\\n\",\n",
    "        \"               'Sandale', 'Chemise', 'Basket', 'Sac', 'Bottine']\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"Forme des donn√©es d'entra√Ænement: {x_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Forme des donn√©es de test: {x_test.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Nombre de classes: {len(class_names)}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation de quelques exemples\\n\",\n",
    "        \"\\n\",\n",
    "        \"Examinons √† quoi ressemblent les images de notre dataset.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(10, 10))\\n\",\n",
    "        \"for i in range(25):\\n\",\n",
    "        \"    plt.subplot(5, 5, i+1)\\n\",\n",
    "        \"    plt.xticks([])\\n\",\n",
    "        \"    plt.yticks([])\\n\",\n",
    "        \"    plt.grid(False)\\n\",\n",
    "        \"    plt.imshow(x_train[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.xlabel(class_names[y_train[i]])\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 3. Tableau de bord des r√©sultats\\n\",\n",
    "        \"\\n\",\n",
    "        \"Cr√©ons une classe pour suivre et comparer les performances des diff√©rents mod√®les que nous allons tester.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"class ModelImprovementDashboard:\\n\",\n",
    "        \"    \\\"\\\"\\\"Classe pour suivre et afficher les r√©sultats des diff√©rentes am√©liorations\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def __init__(self):\\n\",\n",
    "        \"        self.results = []\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def add_result(self, model_name, metrics, notes=\\\"\\\"):\\n\",\n",
    "        \"        \\\"\\\"\\\"Ajoute un r√©sultat au tableau de bord\\\"\\\"\\\"\\n\",\n",
    "        \"        result = {\\n\",\n",
    "        \"            'model_name': model_name,\\n\",\n",
    "        \"            'accuracy': metrics['test_accuracy'],\\n\",\n",
    "        \"            'loss': metrics['test_loss'],\\n\",\n",
    "        \"            'training_time': metrics['training_time'],\\n\",\n",
    "        \"            'epochs': metrics['epochs_completed'],\\n\",\n",
    "        \"            'notes': notes\\n\",\n",
    "        \"        }\\n\",\n",
    "        \"        self.results.append(result)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def show_results(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"Affiche un tableau comparatif des r√©sultats\\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.results:\\n\",\n",
    "        \"            print(\\\"Aucun r√©sultat √† afficher.\\\")\\n\",\n",
    "        \"            return\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Cr√©er un DataFrame\\n\",\n",
    "        \"        df = pd.DataFrame(self.results)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Trier par pr√©cision (descendant)\\n\",\n",
    "        \"        df = df.sort_values(by='accuracy', ascending=False)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Formater les colonnes\\n\",\n",
    "        \"        df['accuracy'] = df['accuracy'].apply(lambda x: f\\\"{x:.2f}%\\\")\\n\",\n",
    "        \"        df['loss'] = df['loss'].apply(lambda x: f\\\"{x:.4f}\\\")\\n\",\n",
    "        \"        df['training_time'] = df['training_time'].apply(lambda x: f\\\"{x:.2f}s\\\")\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        print(\\\"\\\\n=== TABLEAU COMPARATIF DES MOD√àLES ===\\\")\\n\",\n",
    "        \"        print(df)\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        return df\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    def plot_comparison(self):\\n\",\n",
    "        \"        \\\"\\\"\\\"Visualise la comparaison des mod√®les\\\"\\\"\\\"\\n\",\n",
    "        \"        if not self.results:\\n\",\n",
    "        \"            print(\\\"Aucun r√©sultat √† afficher.\\\")\\n\",\n",
    "        \"            return\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Pr√©parer les donn√©es\\n\",\n",
    "        \"        models = [r['model_name'] for r in self.results]\\n\",\n",
    "        \"        accuracies = [float(r['accuracy'].strip('%')) for r in self.results]\\n\",\n",
    "        \"        times = [float(r['training_time'].strip('s')) for r in self.results]\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Cr√©er le graphique\\n\",\n",
    "        \"        plt.figure(figsize=(12, 6))\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Graphique de pr√©cision\\n\",\n",
    "        \"        plt.subplot(1, 2, 1)\\n\",\n",
    "        \"        bars = plt.bar(models, accuracies, color='skyblue')\\n\",\n",
    "        \"        plt.title('Comparaison des pr√©cisions')\\n\",\n",
    "        \"        plt.xlabel('Mod√®le')\\n\",\n",
    "        \"        plt.ylabel('Pr√©cision (%)')\\n\",\n",
    "        \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Ajouter les valeurs sur les barres\\n\",\n",
    "        \"        for bar in bars:\\n\",\n",
    "        \"            height = bar.get_height()\\n\",\n",
    "        \"            plt.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "        \"                     f'{height:.2f}%',\\n\",\n",
    "        \"                     ha='center', va='bottom')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Graphique de temps d'entra√Ænement\\n\",\n",
    "        \"        plt.subplot(1, 2, 2)\\n\",\n",
    "        \"        bars = plt.bar(models, times, color='salmon')\\n\",\n",
    "        \"        plt.title('Comparaison des temps d\\\\'entra√Ænement')\\n\",\n",
    "        \"        plt.xlabel('Mod√®le')\\n\",\n",
    "        \"        plt.ylabel('Temps (secondes)')\\n\",\n",
    "        \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Ajouter les valeurs sur les barres\\n\",\n",
    "        \"        for bar in bars:\\n\",\n",
    "        \"            height = bar.get_height()\\n\",\n",
    "        \"            plt.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "        \"                     f'{height:.2f}s',\\n\",\n",
    "        \"                     ha='center', va='bottom')\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        plt.tight_layout()\\n\",\n",
    "        \"        plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Initialiser le tableau de bord\\n\",\n",
    "        \"dashboard = ModelImprovementDashboard()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 4. Fonctions d'√©valuation de mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"D√©finissons des fonctions pour entra√Æner, √©valuer et visualiser les mod√®les de mani√®re coh√©rente.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def evaluate_model(model, x_train, y_train, x_test, y_test, epochs=5, batch_size=128, data_augmentation=False):\\n\",\n",
    "        \"    \\\"\\\"\\\"Entra√Æne et √©value un mod√®le, retourne les m√©triques de performance\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Configuration pour l'augmentation de donn√©es (si activ√©e)\\n\",\n",
    "        \"    if data_augmentation:\\n\",\n",
    "        \"        train_datagen = ImageDataGenerator(\\n\",\n",
    "        \"            rotation_range=10,\\n\",\n",
    "        \"            width_shift_range=0.1,\\n\",\n",
    "        \"            height_shift_range=0.1,\\n\",\n",
    "        \"            zoom_range=0.1,\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"        train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Callbacks pour am√©liorer l'entra√Ænement\\n\",\n",
    "        \"    callbacks = []\\n\",\n",
    "        \"    if epochs > 5:\\n\",\n",
    "        \"        callbacks = [\\n\",\n",
    "        \"            EarlyStopping(patience=5, restore_best_weights=True),\\n\",\n",
    "        \"            ReduceLROnPlateau(factor=0.2, patience=3, min_lr=0.0001)\\n\",\n",
    "        \"        ]\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Mesure du temps d'entra√Ænement\\n\",\n",
    "        \"    start_time = time.time()\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Entra√Ænement du mod√®le\\n\",\n",
    "        \"    if data_augmentation:\\n\",\n",
    "        \"        history = model.fit(\\n\",\n",
    "        \"            train_generator,\\n\",\n",
    "        \"            epochs=epochs,\\n\",\n",
    "        \"            steps_per_epoch=len(x_train) // batch_size,\\n\",\n",
    "        \"            validation_data=(x_test, y_test),\\n\",\n",
    "        \"            callbacks=callbacks,\\n\",\n",
    "        \"            verbose=1\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        history = model.fit(\\n\",\n",
    "        \"            x_train, y_train,\\n\",\n",
    "        \"            batch_size=batch_size,\\n\",\n",
    "        \"            epochs=epochs,\\n\",\n",
    "        \"            validation_data=(x_test, y_test),\\n\",\n",
    "        \"            callbacks=callbacks,\\n\",\n",
    "        \"            verbose=1\\n\",\n",
    "        \"        )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    training_time = time.time() - start_time\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # √âvaluation du mod√®le\\n\",\n",
    "        \"    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Pr√©parer les m√©triques\\n\",\n",
    "        \"    metrics = {\\n\",\n",
    "        \"        'test_accuracy': test_acc * 100,\\n\",\n",
    "        \"        'test_loss': test_loss,\\n\",\n",
    "        \"        'training_time': training_time,\\n\",\n",
    "        \"        'epochs_completed': len(history.history['loss']),\\n\",\n",
    "        \"        'history': history\\n\",\n",
    "        \"    }\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return metrics\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_training_history(history):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise l'historique d'entra√Ænement\\\"\\\"\\\"\\n\",\n",
    "        \"    plt.figure(figsize=(12, 5))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Graphique de pr√©cision\\n\",\n",
    "        \"    plt.subplot(1, 2, 1)\\n\",\n",
    "        \"    plt.plot(history.history['accuracy'], label='Entra√Ænement')\\n\",\n",
    "        \"    plt.plot(history.history['val_accuracy'], label='Validation')\\n\",\n",
    "        \"    plt.title('√âvolution de la pr√©cision')\\n\",\n",
    "        \"    plt.xlabel('√âpoque')\\n\",\n",
    "        \"    plt.ylabel('Pr√©cision')\\n\",\n",
    "        \"    plt.legend()\\n\",\n",
    "        \"    plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Graphique de perte\\n\",\n",
    "        \"    plt.subplot(1, 2, 2)\\n\",\n",
    "        \"    plt.plot(history.history['loss'], label='Entra√Ænement')\\n\",\n",
    "        \"    plt.plot(history.history['val_loss'], label='Validation')\\n\",\n",
    "        \"    plt.title('√âvolution de la perte')\\n\",\n",
    "        \"    plt.xlabel('√âpoque')\\n\",\n",
    "        \"    plt.ylabel('Perte')\\n\",\n",
    "        \"    plt.legend()\\n\",\n",
    "        \"    plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_confusion_matrix(model, x_test, y_test):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise la matrice de confusion du mod√®le\\\"\\\"\\\"\\n\",\n",
    "        \"    # Pr√©dictions\\n\",\n",
    "        \"    y_pred = model.predict(x_test)\\n\",\n",
    "        \"    y_pred_classes = np.argmax(y_pred, axis=1)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Calculer la matrice de confusion\\n\",\n",
    "        \"    conf_mat = confusion_matrix(y_test, y_pred_classes)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Visualisation\\n\",\n",
    "        \"    plt.figure(figsize=(10, 8))\\n\",\n",
    "        \"    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\\n\",\n",
    "        \"                xticklabels=class_names,\\n\",\n",
    "        \"                yticklabels=class_names)\\n\",\n",
    "        \"    plt.xlabel('Pr√©dit')\\n\",\n",
    "        \"    plt.ylabel('R√©el')\\n\",\n",
    "        \"    plt.title('Matrice de confusion')\\n\",\n",
    "        \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"def show_misclassified_examples(model, x_test, y_test, n=10):\\n\",\n",
    "        \"    \\\"\\\"\\\"Affiche des exemples d'images mal classifi√©es\\\"\\\"\\\"\\n\",\n",
    "        \"    predictions = model.predict(x_test)\\n\",\n",
    "        \"    predicted_classes = np.argmax(predictions, axis=1)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Trouver les erreurs\\n\",\n",
    "        \"    errors = (predicted_classes != y_test)\\n\",\n",
    "        \"    error_indices = np.where(errors)[0]\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    if len(error_indices) == 0:\\n\",\n",
    "        \"        print(\\\"Aucune erreur trouv√©e!\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # S√©lectionner un √©chantillon d'erreurs\\n\",\n",
    "        \"    sample_size = min(n, len(error_indices))\\n\",\n",
    "        \"    sample_indices = np.random.choice(error_indices, size=sample_size, replace=False)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les exemples\\n\",\n",
    "        \"    plt.figure(figsize=(15, 3*sample_size//5 + 3))\\n\",\n",
    "        \"    for i, idx in enumerate(sample_indices):\\n\",\n",
    "        \"        plt.subplot(sample_size//5 + 1, 5, i+1)\\n\",\n",
    "        \"        plt.imshow(x_test[idx].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"        plt.title(f\\\"R√©el: {class_names[y_test[idx]]}\\\\nPr√©dit: {class_names[predicted_classes[idx]]}\\\")\\n\",\n",
    "        \"        plt.axis('off')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 5. Mod√®le de base (sous-optimal)\\n\",\n",
    "        \"\\n\",\n",
    "        \"Commen√ßons par cr√©er et √©valuer un mod√®le CNN de base, volontairement sous-optimal, qui servira de point de r√©f√©rence pour nos am√©liorations.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_baseline_model():\\n\",\n",
    "        \"    \\\"\\\"\\\"Cr√©e un mod√®le CNN de base volontairement sous-performant\\\"\\\"\\\"\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        Flatten(),\\n\",\n",
    "        \"        Dense(16, activation='relu'),\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer=Adam(learning_rate=0.01),  # Learning rate trop √©lev√©\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Cr√©er et afficher le mod√®le de base\\n\",\n",
    "        \"baseline_model = create_baseline_model()\\n\",\n",
    "        \"baseline_model.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Entra√Ænement et √©valuation du mod√®le de base\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"\\\\n--- Mod√®le de base ---\\\")\\n\",\n",
    "        \"baseline_metrics = evaluate_model(baseline_model, x_train, y_train, x_test, y_test, epochs=5)\\n\",\n",
    "        \"print(f\\\"Pr√©cision du mod√®le de base: {baseline_metrics['test_accuracy']:.2f}%\\\")\\n\",\n",
    "        \"print(f\\\"Temps d'entra√Ænement: {baseline_metrics['training_time']:.2f} secondes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser l'historique d'entra√Ænement\\n\",\n",
    "        \"plot_training_history(baseline_metrics['history'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Ajouter au tableau de bord\\n\",\n",
    "        \"dashboard.add_result(\\\"Mod√®le de base\\\", baseline_metrics, \\n\",\n",
    "        \"                     \\\"CNN simple, peu de filtres, learning rate √©lev√©\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Analyse des erreurs du mod√®le de base\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Afficher la matrice de confusion\\n\",\n",
    "        \"plot_confusion_matrix(baseline_model, x_test, y_test)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher des exemples d'erreurs\\n\",\n",
    "        \"print(\\\"\\\\nExemples d'erreurs de classification du mod√®le de base:\\\")\\n\",\n",
    "        \"show_misclassified_examples(baseline_model, x_test, y_test)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### üîç Diagnostic du mod√®le de base\\n\",\n",
    "        \"\\n\",\n",
    "        \"Avant de passer aux am√©liorations, analysons les probl√®mes du mod√®le de base :\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. **Architecture trop simple** : \\n\",\n",
    "        \"   - Seulement 8 filtres dans la couche de convolution\\n\",\n",
    "        \"   - Une seule couche de convolution\\n\",\n",
    "        \"   - Seulement 16 neurones dans la couche dense\\n\",\n",
    "        \"   \\n\",\n",
    "        \"2. **Optimisation probl√©matique** :\\n\",\n",
    "        \"   - Taux d'apprentissage trop √©lev√© (0.01)\\n\",\n",
    "        \"   - Pas de r√©gularisation (dropout, etc.)\\n\",\n",
    "        \"   - Nombre d'√©poques potentiellement insuffisant\\n\",\n",
    "        \"   \\n\",\n",
    "        \"3. **Pr√©traitement minimal** :\\n\",\n",
    "        \"   - Pas d'augmentation de donn√©es\\n\",\n",
    "        \"   - Pas de normalisation batch\\n\",\n",
    "        \"\\n\",\n",
    "        \"Ces observations nous guideront dans nos tentatives d'am√©lioration.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 6. Premi√®re am√©lioration : Architecture plus profonde\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour notre premi√®re am√©lioration, nous allons :\\n\",\n",
    "        \"- Augmenter le nombre de filtres\\n\",\n",
    "        \"- Ajouter une couche de convolution suppl√©mentaire\\n\",\n",
    "        \"- Augmenter le nombre de neurones dans la couche dense\\n\",\n",
    "        \"- R√©duire le taux d'apprentissage\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_improved_model_1():\\n\",\n",
    "        \"    \\\"\\\"\\\"Premier exemple d'am√©lioration: architecture plus profonde\\\"\\\"\\\"\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        Flatten(),\\n\",\n",
    "        \"        Dense(128, activation='relu'),\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer=Adam(learning_rate=0.001),  # Taux d'apprentissage r√©duit\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Cr√©er et afficher le mod√®le am√©lior√© 1\\n\",\n",
    "        \"improved_model_1 = create_improved_model_1()\\n\",\n",
    "        \"improved_model_1.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Entra√Ænement et √©valuation du mod√®le am√©lior√© 1\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"\\\\n--- Mod√®le am√©lior√© 1 ---\\\")\\n\",\n",
    "        \"improved_metrics_1 = evaluate_model(improved_model_1, x_train, y_train, x_test, y_test, epochs=10)\\n\",\n",
    "        \"print(f\\\"Pr√©cision du mod√®le am√©lior√© 1: {improved_metrics_1['test_accuracy']:.2f}%\\\")\\n\",\n",
    "        \"print(f\\\"Temps d'entra√Ænement: {improved_metrics_1['training_time']:.2f} secondes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser l'historique d'entra√Ænement\\n\",\n",
    "        \"plot_training_history(improved_metrics_1['history'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Ajouter au tableau de bord\\n\",\n",
    "        \"dashboard.add_result(\\\"Mod√®le am√©lior√© 1\\\", improved_metrics_1, \\n\",\n",
    "        \"                    \\\"Plus de filtres, couche suppl√©mentaire, learning rate plus bas\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Analyse des r√©sultats du mod√®le am√©lior√© 1\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Visualiser les r√©sultats de l'am√©lioration\\n\",\n",
    "        \"print(\\\"Comparaison des mod√®les jusqu'√† pr√©sent:\\\")\\n\",\n",
    "        \"dashboard.show_results()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Voir les nouvelles erreurs\\n\",\n",
    "        \"print(\\\"\\\\nExemples d'erreurs apr√®s la premi√®re am√©lioration:\\\")\\n\",\n",
    "        \"show_misclassified_examples(improved_model_1, x_test, y_test)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 7. Deuxi√®me am√©lioration : R√©gularisation et augmentation de donn√©es\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour notre deuxi√®me am√©lioration, nous allons :\\n\",\n",
    "        \"- Ajouter du dropout pour √©viter le surapprentissage\\n\",\n",
    "        \"- Int√©grer la normalisation par batch (batch normalization)\\n\",\n",
    "        \"- Utiliser l'augmentation de donn√©es pour am√©liorer la g√©n√©ralisation\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Architecture du mod√®le am√©lior√© 2\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_improved_model_2():\\n\",\n",
    "        \"    \\\"\\\"\\\"Deuxi√®me exemple d'am√©lioration: ajout de dropout et batch normalization\\\"\\\"\\\"\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        # Premi√®re couche de convolution avec batch normalization\\n\",\n",
    "        \"        Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\\n\",\n",
    "        \"        BatchNormalization(),\\n\",\n",
    "        \"        Activation('relu'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Deuxi√®me couche de convolution avec batch normalization\\n\",\n",
    "        \"        Conv2D(64, (3, 3), padding='same'),\\n\",\n",
    "        \"        BatchNormalization(),\\n\",\n",
    "        \"        Activation('relu'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2)),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Aplatissement\\n\",\n",
    "        \"        Flatten(),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couche dense avec batch normalization et dropout\\n\",\n",
    "        \"        Dense(128),\\n\",\n",
    "        \"        BatchNormalization(),\\n\",\n",
    "        \"        Activation('relu'),\\n\",\n",
    "        \"        Dropout(0.5),  # 50% de dropout pour la r√©gularisation\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couche de sortie\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer=Adam(learning_rate=0.001),\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Cr√©er et afficher le mod√®le am√©lior√© 2\\n\",\n",
    "        \"improved_model_2 = create_improved_model_2()\\n\",\n",
    "        \"improved_model_2.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Entra√Ænement avec augmentation de donn√©es\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour cette am√©lioration, nous allons √©galement utiliser l'augmentation de donn√©es qui permet de g√©n√©rer artificiellement plus d'exemples d'entra√Ænement en appliquant des transformations aux images existantes. Cela am√©liore la robustesse du mod√®le face aux variations qu'il pourrait rencontrer en conditions r√©elles.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"\\\\n--- Mod√®le am√©lior√© 2 (avec augmentation de donn√©es) ---\\\")\\n\",\n",
    "        \"improved_metrics_2 = evaluate_model(improved_model_2, x_train, y_train, x_test, y_test, \\n\",\n",
    "        \"                                   epochs=15, data_augmentation=True)\\n\",\n",
    "        \"print(f\\\"Pr√©cision du mod√®le am√©lior√© 2: {improved_metrics_2['test_accuracy']:.2f}%\\\")\\n\",\n",
    "        \"print(f\\\"Temps d'entra√Ænement: {improved_metrics_2['training_time']:.2f} secondes\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser l'historique d'entra√Ænement\\n\",\n",
    "        \"plot_training_history(improved_metrics_2['history'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Ajouter au tableau de bord\\n\",\n",
    "        \"dashboard.add_result(\\\"Mod√®le am√©lior√© 2\\\", improved_metrics_2, \\n\",\n",
    "        \"                    \\\"Dropout, BatchNorm, augmentation de donn√©es\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Analyse des r√©sultats du mod√®le am√©lior√© 2\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Visualiser la matrice de confusion\\n\",\n",
    "        \"plot_confusion_matrix(improved_model_2, x_test, y_test)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher des exemples d'erreurs\\n\",\n",
    "        \"print(\\\"\\\\nExemples d'erreurs apr√®s la deuxi√®me am√©lioration:\\\")\\n\",\n",
    "        \"show_misclassified_examples(improved_model_2, x_test, y_test)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Comparer tous les mod√®les\\n\",\n",
    "        \"dashboard.show_results()\\n\",\n",
    "        \"dashboard.plot_comparison()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 8. Cr√©ation de votre propre mod√®le am√©lior√©\\n\",\n",
    "        \"\\n\",\n",
    "        \"C'est maintenant √† vous de concevoir votre propre am√©lioration! Vous pouvez explorer diff√©rentes architectures, techniques d'optimisation, ou combinaisons d'approches.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Voici quelques pistes d'am√©lioration possibles:\\n\",\n",
    "        \"- Essayer diff√©rentes architectures (plus/moins de couches, filtres, etc.)\\n\",\n",
    "        \"- Exp√©rimenter avec d'autres optimiseurs (RMSprop, SGD avec momentum, etc.)\\n\",\n",
    "        \"- Tester diff√©rentes techniques de r√©gularisation\\n\",\n",
    "        \"- Modifier les param√®tres d'augmentation de donn√©es\\n\",\n",
    "        \"- Utiliser des connexions r√©siduelles (comme dans les architectures ResNet)\\n\",\n",
    "        \"- Combiner les meilleures pratiques des mod√®les pr√©c√©dents\"\n",
    "      ]\n",
    "    },\n",
    ".\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couche de sortie\\n\",\n",
    "        \"        Dense(10, activation='softmax')\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Compilation\\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer='adam',  # Modifiez selon vos pr√©f√©rences\\n\",\n",
    "        \"        loss='sparse_categorical_crossentropy',\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Si vous √™tes pr√™t √† tester votre mod√®le, d√©commentez les lignes suivantes\\n\",\n",
    "        \"#your_model = create_your_improved_model()\\n\",\n",
    "        \"#your_model.summary()\"\n",
    "      ]\n",
    "    },\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
