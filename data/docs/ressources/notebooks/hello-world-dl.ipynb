{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1951236794.py, line 106)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"cell_type\": \"code\",\\n\",\u001b[39m\n                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üöÄ Hello World du Deep Learning\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Reconnaissance de chiffres manuscrits avec TensorFlow et Keras\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Objectifs de ce notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Charger et pr√©parer un jeu de donn√©es de chiffres manuscrits\\n\",\n",
    "    \"- Cr√©er un r√©seau de neurones simple\\n\",\n",
    "    \"- Entra√Æner le mod√®le\\n\",\n",
    "    \"- Visualiser les r√©sultats\\n\",\n",
    "    \"- Tester le mod√®le avec vos propres dessins\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Importation des biblioth√®ques n√©cessaires\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow import keras\\n\",\n",
    "    \"from tensorflow.keras import layers\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V√©rification de la version de TensorFlow\\n\",\n",
    "    \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\\n\",\n",
    "    \"print(f\\\"Keras version: {keras.__version__}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V√©rification du GPU (si disponible)\\n\",\n",
    "    \"print(\\\"GPU disponible :\\\", tf.test.is_gpu_available())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Chargement du dataset MNIST\\n\",\n",
    "    \"(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Pr√©traitement des donn√©es\\n\",\n",
    "    \"X_train = X_train.reshape((60000, 28, 28, 1)) / 255.0\\n\",\n",
    "    \"X_test = X_test.reshape((10000, 28, 28, 1)) / 255.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Conversion des labels en cat√©gories\\n\",\n",
    "    \"y_train = keras.utils.to_categorical(y_train)\\n\",\n",
    "    \"y_test = keras.utils.to_categorical(y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Affichage de quelques exemples\\n\",\n",
    "    \"plt.figure(figsize=(10, 2))\\n\",\n",
    "    \"for i in range(10):\\n\",\n",
    "    \"    plt.subplot(1, 10, i+1)\\n\",\n",
    "    \"    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "    \"    plt.axis('off')\\n\",\n",
    "    \"plt.suptitle(\\\"Exemples de chiffres manuscrits\\\")\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Nombre d'exemples d'entra√Ænement : {X_train.shape[0]}\\\")\\n\",\n",
    "    \"print(f\\\"Nombre d'exemples de test : {X_test.shape[0]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Cr√©ation du mod√®le de r√©seau de neurones\\n\",\n",
    "    \"model = keras.Sequential([\\n\",\n",
    "    \"    # Couche de convolution\\n\",\n",
    "    \"    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n",
    "    \"    layers.MaxPooling2D((2, 2)),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Couche de convolution suppl√©mentaire\\n\",\n",
    "    \"    layers.Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "    \"    layers.MaxPooling2D((2, 2)),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Aplatissement\\n\",\n",
    "    \"    layers.Flatten(),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Couche dense\\n\",\n",
    "    \"    layers.Dense(64, activation='relu'),\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Couche de sortie\\n\",\n",
    "    \"    layers.Dense(10, activation='softmax')\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Compilation du mod√®le\\n\",\n",
    "    \"model.compile(\\n\",\n",
    "    \"    optimizer='adam',\\n\",\n",
    "    \"    loss='categorical_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Affichage du r√©sum√© du mod√®le\\n\",\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\\n\",\n",
    "   \"execution_count\": null,\\n\",\n",
    "   \"metadata\": {},\\n\",\n",
    "   \"source\": [\n",
    "    \"# Entra√Ænement du mod√®le\\n\",\n",
    "    \"# Note : Nombre d'√©poques r√©duit pour la d√©monstration\\n\",\n",
    "    \"history = model.fit(\\n\",\n",
    "    \"    X_train, y_train,\\n\",\n",
    "    \"    epochs=5,\\n\",\n",
    "    \"    batch_size=64,\\n\",\n",
    "    \"    validation_split=0.2,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# √âvaluation du mod√®le\\n\",\n",
    "    \"test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\\n\",\n",
    "    \"print(f\\\"\\\\nPr√©cision sur l'ensemble de test : {test_accuracy*100:.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\\n\",\n",
    "   \"execution_count\": null,\\n\",\n",
    "   \"metadata\": {},\\n\",\n",
    "   \"source\": [\n",
    "    \"# Visualisation de la pr√©cision et de la perte\\n\",\n",
    "    \"plt.figure(figsize=(12, 4))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Pr√©cision\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(history.history['accuracy'], label='Pr√©cision entra√Ænement')\\n\",\n",
    "    \"plt.plot(history.history['val_accuracy'], label='Pr√©cision validation')\\n\",\n",
    "    \"plt.title('Pr√©cision du mod√®le')\\n\",\n",
    "    \"plt.xlabel('√âpoque')\\n\",\n",
    "    \"plt.ylabel('Pr√©cision')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Perte\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.plot(history.history['loss'], label='Perte entra√Ænement')\\n\",\n",
    "    \"plt.plot(history.history['val_loss'], label='Perte validation')\\n\",\n",
    "    \"plt.title('Perte du mod√®le')\\n\",\n",
    "    \"plt.xlabel('√âpoque')\\n\",\n",
    "    \"plt.ylabel('Perte')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\\n\",\n",
    "   \"execution_count\": null,\\n\",\n",
    "   \"metadata\": {},\\n\",\n",
    "   \"source\": [\n",
    "    \"# Pr√©dictions et visualisation\\n\",\n",
    "    \"# Pr√©dire sur quelques images de test\\n\",\n",
    "    \"predictions = model.predict(X_test[:10])\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(15, 6))\\n\",\n",
    "    \"for i in range(10):\\n\",\n",
    "    \"    plt.subplot(2, 10, i+1)\\n\",\n",
    "    \"    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "    \"    plt.axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.subplot(2, 10, i+11)\\n\",\n",
    "    \"    plt.bar(range(10), predictions[i])\\n\",\n",
    "    \"    plt.title(f\\\"Pr√©diction: {np.argmax(predictions[i])}\\\")\\n\",\n",
    "    \"    plt.xticks(range(10))\\n\",\n",
    "    \"    plt.ylim(0, 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.suptitle(\\\"Pr√©dictions du mod√®le\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\\n\",\n",
    "   \"metadata\": {},\\n\",\n",
    "   \"source\": [\n",
    "    \"## ü§î Questions de r√©flexion\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Que se passe-t-il si vous augmentez le nombre d'√©poques ?\\n\",\n",
    "    \"2. Comment changeriez-vous l'architecture du r√©seau pour am√©liorer les performances ?\\n\",\n",
    "    \"3. Quelles diff√©rences observez-vous entre la pr√©cision d'entra√Ænement et de validation ?\\n\",\n",
    "    \"\\n\",\n",
    "    \"## üöÄ D√©fis\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Essayez de modifier le nombre de neurones dans les couches denses\\n\",\n",
    "    \"- Changez la fonction d'activation dans certaines couches\\n\",\n",
    "    \"- Ajoutez une couche de dropout pour r√©duire le surapprentissage\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
