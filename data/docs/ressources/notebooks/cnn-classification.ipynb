{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# CNN pour la classification d'images - MNIST\\n\",\n",
    "        \"\\n\",\n",
    "        \"## BTS SIO  - S√©ance 2: Types de r√©seaux de neurones\\n\",\n",
    "        \"\\n\",\n",
    "        \"Ce notebook vous guidera √† travers l'impl√©mentation et l'utilisation d'un r√©seau de neurones convolutif (CNN) pour la classification d'images, en utilisant le c√©l√®bre dataset MNIST des chiffres manuscrits.\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Objectifs d'apprentissage:\\n\",\n",
    "        \"- Comprendre l'architecture d'un r√©seau convolutif (CNN)\\n\",\n",
    "        \"- Impl√©menter un CNN avec TensorFlow/Keras\\n\",\n",
    "        \"- Visualiser les filtres et feature maps\\n\",\n",
    "        \"- Analyser les performances du mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Pr√©requis:\\n\",\n",
    "        \"- Connaissances de base en Python\\n\",\n",
    "        \"- Avoir suivi la s√©ance 1 d'introduction au Deep Learning\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 1. Configuration de l'environnement\\n\",\n",
    "        \"\\n\",\n",
    "        \"Commen√ßons par importer les biblioth√®ques n√©cessaires.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tensorflow.keras.models import Sequential\\n\",\n",
    "        \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\\n\",\n",
    "        \"from tensorflow.keras.utils import to_categorical\\n\",\n",
    "        \"from tensorflow.keras.datasets import mnist\\n\",\n",
    "        \"import time\\n\",\n",
    "        \"import seaborn as sns\\n\",\n",
    "        \"from sklearn.metrics import confusion_matrix\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Configuration pour reproductibilit√©\\n\",\n",
    "        \"np.random.seed(42)\\n\",\n",
    "        \"tf.random.set_seed(42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# V√©rifier la version de TensorFlow\\n\",\n",
    "        \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 2. Chargement et pr√©paration du dataset MNIST\\n\",\n",
    "        \"\\n\",\n",
    "        \"Le dataset MNIST contient 70,000 images de chiffres manuscrits de taille 28x28 pixels.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"Chargement des donn√©es MNIST...\\\")\\n\",\n",
    "        \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher les dimensions des donn√©es\\n\",\n",
    "        \"print(f\\\"Dimensions de X_train: {X_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Dimensions de y_train: {y_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Dimensions de X_test: {X_test.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Dimensions de y_test: {y_test.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Nombre de classes: {len(np.unique(y_train))}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Pr√©paration des donn√©es pour le CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour utiliser nos images avec un CNN, nous devons :\\n\",\n",
    "        \"1. Ajouter une dimension pour le canal (les images sont en niveaux de gris, donc 1 seul canal)\\n\",\n",
    "        \"2. Normaliser les valeurs de pixels entre 0 et 1\\n\",\n",
    "        \"3. Convertir les √©tiquettes en format one-hot encoding\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Redimensionnement et normalisation\\n\",\n",
    "        \"X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Conversion des √©tiquettes en cat√©gories one-hot\\n\",\n",
    "        \"y_train_onehot = to_categorical(y_train, 10)\\n\",\n",
    "        \"y_test_onehot = to_categorical(y_test, 10)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"Nouvelle forme de X_train: {X_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Nouvelle forme de y_train_onehot: {y_train_onehot.shape}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation de quelques exemples\\n\",\n",
    "        \"\\n\",\n",
    "        \"Regardons √† quoi ressemblent nos donn√©es.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(10, 5))\\n\",\n",
    "        \"for i in range(10):\\n\",\n",
    "        \"    plt.subplot(2, 5, i+1)\\n\",\n",
    "        \"    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.title(f\\\"Chiffre: {y_train[i]}\\\")\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 3. Cr√©ation d'un mod√®le CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"Un CNN est un type de r√©seau de neurones sp√©cialis√© pour traiter des donn√©es ayant une structure en grille, comme les images. Les principales couches sont :\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. **Couches de convolution (Conv2D)** : D√©tectent des caract√©ristiques locales (lignes, formes...)\\n\",\n",
    "        \"2. **Couches de pooling (MaxPooling2D)** : R√©duisent la dimension des donn√©es\\n\",\n",
    "        \"3. **Couches denses (Dense)** : Effectuent la classification finale\\n\",\n",
    "        \"\\n\",\n",
    "        \"Nous allons cr√©er un CNN simple avec 2 couches de convolution pour classifier les chiffres MNIST.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Cr√©er un mod√®le CNN\\n\",\n",
    "        \"model = Sequential([\\n\",\n",
    "        \"    # Premi√®re couche de convolution\\n\",\n",
    "        \"    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv1'),\\n\",\n",
    "        \"    MaxPooling2D((2, 2), name='pool1'),\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Deuxi√®me couche de convolution\\n\",\n",
    "        \"    Conv2D(64, (3, 3), activation='relu', name='conv2'),\\n\",\n",
    "        \"    MaxPooling2D((2, 2), name='pool2'),\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Aplatissement pour passer aux couches denses\\n\",\n",
    "        \"    Flatten(name='flatten'),\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Couches denses (fully connected)\\n\",\n",
    "        \"    Dense(128, activation='relu', name='dense1'),\\n\",\n",
    "        \"    Dropout(0.5, name='dropout1'),  # √âvite le surapprentissage\\n\",\n",
    "        \"    Dense(10, activation='softmax', name='output')  # 10 classes (chiffres 0-9)\\n\",\n",
    "        \"])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Compiler le mod√®le\\n\",\n",
    "        \"model.compile(\\n\",\n",
    "        \"    optimizer='adam',\\n\",\n",
    "        \"    loss='categorical_crossentropy',\\n\",\n",
    "        \"    metrics=['accuracy']\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher le r√©sum√© de l'architecture\\n\",\n",
    "        \"model.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 4. Entra√Ænement du mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"Entra√Ænons maintenant notre CNN sur les donn√©es MNIST.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Entra√Ænement du mod√®le\\n\",\n",
    "        \"start_time = time.time()\\n\",\n",
    "        \"\\n\",\n",
    "        \"history = model.fit(\\n\",\n",
    "        \"    X_train, \\n\",\n",
    "        \"    y_train_onehot, \\n\",\n",
    "        \"    batch_size=128, \\n\",\n",
    "        \"    epochs=5,  # Nombre r√©duit d'√©poques pour la d√©monstration\\n\",\n",
    "        \"    validation_split=0.2,  # 20% des donn√©es d'entra√Ænement pour la validation\\n\",\n",
    "        \"    verbose=1\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"training_time = time.time() - start_time\\n\",\n",
    "        \"print(f\\\"\\\\nTemps d'entra√Ænement: {training_time:.2f} secondes\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation de l'√©volution de l'entra√Ænement\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Graphique de pr√©cision\\n\",\n",
    "        \"plt.subplot(1, 2, 1)\\n\",\n",
    "        \"plt.plot(history.history['accuracy'], label='Entra√Ænement')\\n\",\n",
    "        \"plt.plot(history.history['val_accuracy'], label='Validation')\\n\",\n",
    "        \"plt.title('√âvolution de la pr√©cision')\\n\",\n",
    "        \"plt.xlabel('√âpoque')\\n\",\n",
    "        \"plt.ylabel('Pr√©cision')\\n\",\n",
    "        \"plt.legend()\\n\",\n",
    "        \"plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Graphique de perte\\n\",\n",
    "        \"plt.subplot(1, 2, 2)\\n\",\n",
    "        \"plt.plot(history.history['loss'], label='Entra√Ænement')\\n\",\n",
    "        \"plt.plot(history.history['val_loss'], label='Validation')\\n\",\n",
    "        \"plt.title('√âvolution de la perte')\\n\",\n",
    "        \"plt.xlabel('√âpoque')\\n\",\n",
    "        \"plt.ylabel('Perte')\\n\",\n",
    "        \"plt.legend()\\n\",\n",
    "        \"plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 5. √âvaluation du mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"√âvaluons notre mod√®le sur l'ensemble de test.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# √âvaluation sur l'ensemble de test\\n\",\n",
    "        \"test_loss, test_acc = model.evaluate(X_test, y_test_onehot, verbose=1)\\n\",\n",
    "        \"print(f\\\"Pr√©cision sur l'ensemble de test: {test_acc*100:.2f}%\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Pr√©dictions\\n\",\n",
    "        \"y_pred = model.predict(X_test)\\n\",\n",
    "        \"y_pred_classes = np.argmax(y_pred, axis=1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Matrice de confusion\\n\",\n",
    "        \"conf_mat = confusion_matrix(y_test, y_pred_classes)\\n\",\n",
    "        \"plt.figure(figsize=(10, 8))\\n\",\n",
    "        \"sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\\n\",\n",
    "        \"plt.xlabel('Pr√©dit')\\n\",\n",
    "        \"plt.ylabel('R√©el')\\n\",\n",
    "        \"plt.title('Matrice de confusion')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation des exemples mal classifi√©s\\n\",\n",
    "        \"\\n\",\n",
    "        \"Explorons quelques exemples que notre mod√®le a mal classifi√©s.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Identifier les erreurs\\n\",\n",
    "        \"misclassified_indices = np.where(y_pred_classes != y_test)[0]\\n\",\n",
    "        \"misclassified_count = len(misclassified_indices)\\n\",\n",
    "        \"print(f\\\"Nombre total d'erreurs: {misclassified_count} sur {len(y_test)} images de test\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher quelques exemples mal classifi√©s\\n\",\n",
    "        \"num_examples = min(10, misclassified_count)\\n\",\n",
    "        \"plt.figure(figsize=(15, 6))\\n\",\n",
    "        \"\\n\",\n",
    "        \"for i, idx in enumerate(misclassified_indices[:num_examples]):\\n\",\n",
    "        \"    plt.subplot(2, 5, i+1)\\n\",\n",
    "        \"    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.title(f\\\"R√©el: {y_test[idx]}\\\\nPr√©dit: {y_pred_classes[idx]}\\\")\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### üß† R√©flexion sur les erreurs\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Question**: En observant les exemples mal classifi√©s, quelles pourraient √™tre les raisons de ces erreurs? Notez vos observations et hypoth√®ses ci-dessous.\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Points √† consid√©rer:**\\n\",\n",
    "        \"- Certains chiffres sont-ils plus souvent confondus que d'autres?\\n\",\n",
    "        \"- Quelles caract√©ristiques visuelles communes peuvent expliquer les erreurs?\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"*√âcrivez vos observations ici...*\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 6. Visualisation des filtres et feature maps\\n\",\n",
    "        \"\\n\",\n",
    "        \"Une des grandes forces des CNNs est leur interpr√©tabilit√© visuelle. Explorons ce que le r√©seau \\\"voit\\\" r√©ellement.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Fonction pour visualiser les filtres de convolution\\n\",\n",
    "        \"def visualize_filters(model, layer_name, num_filters=8):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise les filtres d'une couche de convolution\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # R√©cup√©rer les poids du filtre de la couche sp√©cifi√©e\\n\",\n",
    "        \"    filters, biases = model.get_layer(layer_name).get_weights()\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Normaliser les filtres pour une meilleure visualisation\\n\",\n",
    "        \"    f_min, f_max = filters.min(), filters.max()\\n\",\n",
    "        \"    filters = (filters - f_min) / (f_max - f_min)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les premiers filtres\\n\",\n",
    "        \"    plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"    for i in range(num_filters):\\n\",\n",
    "        \"        plt.subplot(2, 4, i+1)\\n\",\n",
    "        \"        # Pour la premi√®re couche de convolution, les filtres sont 3D (hauteur, largeur, canaux)\\n\",\n",
    "        \"        # Nous affichons le filtre pour le premier canal (0)\\n\",\n",
    "        \"        plt.imshow(filters[:, :, 0, i], cmap='viridis')\\n\",\n",
    "        \"        plt.title(f'Filtre {i+1}')\\n\",\n",
    "        \"        plt.axis('off')\\n\",\n",
    "        \"    plt.suptitle(f'Filtres de la couche {layer_name}')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser les filtres de la premi√®re couche de convolution\\n\",\n",
    "        \"visualize_filters(model, 'conv1')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation des feature maps (cartes d'activation)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def visualize_feature_maps(model, image, layer_name, num_features=8):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise les feature maps (activations) d'une couche pour une image donn√©e\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Cr√©er un mod√®le qui renvoie les activations de la couche sp√©cifi√©e\\n\",\n",
    "        \"    layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Obtenir les activations pour une image\\n\",\n",
    "        \"    feature_maps = layer_model.predict(image.reshape(1, 28, 28, 1))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les premi√®res cartes d'activation\\n\",\n",
    "        \"    plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"    for i in range(min(num_features, feature_maps.shape[3])):\\n\",\n",
    "        \"        plt.subplot(2, 4, i+1)\\n\",\n",
    "        \"        plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\\n\",\n",
    "        \"        plt.title(f'Feature {i+1}')\\n\",\n",
    "        \"        plt.axis('off')\\n\",\n",
    "        \"    plt.suptitle(f'Feature Maps de la couche {layer_name}')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Choisir une image de test\\n\",\n",
    "        \"sample_idx = 12  # Vous pouvez essayer avec diff√©rents indices\\n\",\n",
    "        \"sample_image = X_test[sample_idx]\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher l'image originale\\n\",\n",
    "        \"plt.figure(figsize=(3, 3))\\n\",\n",
    "        \"plt.imshow(sample_image.reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"plt.title(f\\\"Chiffre: {y_test[sample_idx]}\\\")\\n\",\n",
    "        \"plt.axis('off')\\n\",\n",
    "        \"plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser les feature maps pour chaque couche de convolution\\n\",\n",
    "        \"print(\\\"Feature maps de la premi√®re couche de convolution:\\\")\\n\",\n",
    "        \"visualize_feature_maps(model, sample_image, 'conv1')\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Feature maps de la deuxi√®me couche de convolution:\\\")\\n\",\n",
    "        \"visualize_feature_maps(model, sample_image, 'conv2')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### üí° Interpr√©tation des feature maps\\n\",\n",
    "        \"\\n\",\n",
    "        \"Les feature maps nous montrent ce que \\\"voit\\\" chaque filtre de convolution :\\n\",\n",
    "        \"\\n\",\n",
    "        \"- **Premi√®re couche** : D√©tecte principalement des caract√©ristiques de base comme les bords et les contours\\n\",\n",
    "        \"- **Deuxi√®me couche** : Combine ces caract√©ristiques de base pour d√©tecter des formes plus complexes\\n\",\n",
    "        \"\\n\",\n",
    "        \"Cette hi√©rarchie de repr√©sentations est ce qui rend les CNNs si puissants pour la vision par ordinateur.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 7. Test avec des images bruit√©es\\n\",\n",
    "        \"\\n\",\n",
    "        \"Testons la robustesse de notre mod√®le face √† des perturbations.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Fonction pour ajouter du bruit aux images\\n\",\n",
    "        \"def add_noise(images, noise_level=0.2):\\n\",\n",
    "        \"    \\\"\\\"\\\"Ajoute du bruit gaussien aux images\\\"\\\"\\\"\\n\",\n",
    "        \"    noisy_images = images.copy()\\n\",\n",
    "        \"    noise = np.random.normal(0, noise_level, images.shape)\\n\",\n",
    "        \"    noisy_images = noisy_images + noise\\n\",\n",
    "        \"    # Assurer que les valeurs restent entre 0 et 1\\n\",\n",
    "        \"    return np.clip(noisy_images, 0, 1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Cr√©er des versions bruit√©es de quelques images de test\\n\",\n",
    "        \"num_test_images = 5\\n\",\n",
    "        \"test_samples = X_test[:num_test_images]\\n\",\n",
    "        \"noisy_samples = add_noise(test_samples, noise_level=0.3)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser les images originales et bruit√©es\\n\",\n",
    "        \"plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"for i in range(num_test_images):\\n\",\n",
    "        \"    # Image originale\\n\",\n",
    "        \"    plt.subplot(2, num_test_images, i+1)\\n\",\n",
    "        \"    plt.imshow(test_samples[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.title(f\\\"Original: {y_test[i]}\\\")\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Image bruit√©e\\n\",\n",
    "        \"    plt.subplot(2, num_test_images, i+num_test_images+1)\\n\",\n",
    "        \"    plt.imshow(noisy_samples[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Pr√©dire sur les images bruit√©es\\n\",\n",
    "        \"noisy_predictions = model.predict(noisy_samples)\\n\",\n",
    "        \"noisy_pred_classes = np.argmax(noisy_predictions, axis=1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher les r√©sultats\\n\",\n",
    "        \"print(\\\"R√©sultats des pr√©dictions sur les images bruit√©es:\\\")\\n\",\n",
    "        \"for i in range(num_test_images):\\n\",\n",
    "        \"    status = \\\"‚úì\\\" if noisy_pred_classes[i] == y_test[i] else \\\"‚úó\\\"\\n\",\n",
    "        \"    print(f\\\"Image {i+1} - R√©el: {y_test[i]}, Pr√©dit: {noisy_pred_classes[i]} {status}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Calculer la pr√©cision sur les images bruit√©es\\n\",\n",
    "        \"accuracy_on_noisy = np.mean(noisy_pred_classes == y_test[:num_test_images]) * 100\\n\",\n",
    "        \"print(f\\\"\\\\nPr√©cision sur les images bruit√©es: {accuracy_on_noisy:.1f}%\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 8. Exercice : Am√©lioration du mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"√Ä vous de jouer ! Essayez de modifier l'architecture du mod√®le pour am√©liorer ses performances. Voici quelques suggestions :\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. Ajouter plus de couches de convolution\\n\",\n",
    "        \"2. Modifier le nombre de filtres\\n\",\n",
    "        \"3. Changer la taille des filtres\\n\",\n",
    "        \"4. Ajuster les param√®tres d'entra√Ænement (epochs, batch_size)\\n\",\n",
    "        \"\\n\",\n",
    "        \"Copiez le code de cr√©ation du mod√®le ci-dessous et modifiez-le :\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# VOTRE CODE ICI\\n\",\n",
    "        \"# Cr√©ez votre propre mod√®le am√©lior√©\\n\",\n",
    "        \"\\n\",\n",
    "        \"improved_model = Sequential([\\n\",\n",
    "        \"    # Modifiez l'architecture ici\\n\",\n",
    "        \"    \\n\",\n",
    "        \"])\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Compiler le mod√®le\\n\",\n",
    "        \"improved_model.compile(\\n\",\n",
    "        \"    optimizer='adam',\\n\",\n",
    "        \"    loss='categorical_crossentropy',\\n\",\n",
    "        \"    metrics=['accuracy']\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher le r√©sum√©\\n\",\n",
    "        \"improved_model.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Entra√Ænez votre mod√®le am√©lior√©\\n\",\n",
    "        \"# history = improved_model.fit(...)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 9. Conclusion\\n\",\n",
    "        \"\\n\",\n",
    "        \"Dans ce notebook, vous avez :\\n\",\n",
    "        \"- Cr√©√© et entra√Æn√© un r√©seau de neurones convolutif (CNN) pour la classification d'images\\n\",\n",
    "        \"- Visualis√© les filtres et les feature maps pour comprendre ce que \\\"voit\\\" le r√©seau\\n\",\n",
    "        \"- √âvalu√© les performances du mod√®le et sa robustesse face au bruit\\n\",\n",
    "        \"\\n\",\n",
    "        \"Les CNN sont la base de nombreuses applications modernes de vision par ordinateur comme la reconnaissance faciale, la d√©tection d'objets, et bien d'autres.\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.8.5\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
