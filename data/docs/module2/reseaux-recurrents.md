# üîç Phase 2 : Mini-projet RNN pour le traitement du langage

![RNN Architecture](https://images.unsplash.com/photo-1498050108023-c5249f4df085?auto=format&fit=crop&q=80&w=1000&h=300)

## üéØ Objectifs de la phase

Dans cette phase, vous allez :

- Comprendre les principes des r√©seaux r√©currents (RNN) et de leurs variantes (LSTM, GRU)
- Impl√©menter un mod√®le LSTM pour l'analyse de sentiment
- Visualiser et interpr√©ter le fonctionnement interne d'un RNN
- Analyser les performances du mod√®le sur des donn√©es textuelles

## üß© Partie 1: Principes des RNN (20 min)

### üìä Architecture et fonctionnement des RNN

Les r√©seaux de neurones r√©currents (RNN) sont con√ßus sp√©cifiquement pour traiter des donn√©es s√©quentielles comme le texte, les s√©ries temporelles ou les donn√©es audio. Contrairement aux r√©seaux classiques qui traitent chaque entr√©e ind√©pendamment, les RNN maintiennent un "√©tat interne" qui leur permet de se souvenir des informations pr√©c√©dentes.

### Probl√©matique : Pourquoi les RNN ?

Imaginons que vous surveillez des logs de s√©curit√© :
- Un r√©seau classique ne verrait que des entr√©es isol√©es, sans comprendre leur s√©quence
- Un RNN, lui, se souvient des √©v√©nements pr√©c√©dents pour d√©tecter des patterns suspects

### Le RNN expliqu√© avec l'analogie du carnet de notes

**Analogie du carnet de notes** :
1. Vous analysez un rapport d'incident et prenez des notes importantes
2. √Ä chaque nouvelle section du rapport, vous :
   - Lisez le nouveau contenu (nouvelle entr√©e)
   - Consultez vos notes pr√©c√©dentes (√©tat cach√© / m√©moire)
   - Mettez √† jour vos notes avec les informations les plus pertinentes
   - Utilisez la combinaison de la nouvelle section et de vos notes pour comprendre l'incident

**Dans un RNN** :
1. Le r√©seau traite les donn√©es s√©quentiellement (mot par mot, √©v√©nement par √©v√©nement)
2. √Ä chaque √©tape, il combine :
   - L'entr√©e actuelle (ex : le mot actuel)
   - Son "√©tat de m√©moire" (ce qu'il a retenu des mots pr√©c√©dents)
3. Il produit :
   - Une sortie pour l'√©tape actuelle (ex: pr√©diction partielle)
   - Un nouvel √©tat de m√©moire pour l'√©tape suivante

**Avantages pour un d√©veloppeur d'applications** :
- Traitement de s√©quences de longueur variable
- Capacit√© √† "m√©moriser" des informations importantes
- Applications diverses : analyse de texte, traduction, g√©n√©ration de contenu

## Les LSTM (Long Short-Term Memory) en langage simple

### Solution au probl√®me de m√©moire

Les RNN classiques ont du mal √† retenir les informations sur de longues s√©quences - c'est le probl√®me du "gradient qui s'√©vanouit". Les cellules LSTM ont √©t√© con√ßues pour r√©soudre ce probl√®me.

**Analogie du rapport de s√©curit√© avec syst√®me de marquage** :
- Vous avez maintenant un syst√®me pour marquer les informations importantes dans votre rapport
- Vous pouvez d√©cider explicitement quelles informations :
  * M√©ritent d'√™tre conserv√©es pour l'analyse finale
  * Doivent √™tre mises √† jour avec de nouvelles donn√©es
  * Sont pertinentes pour l'incident en cours

### Les portes (gates) expliqu√©es simplement

Au lieu d'une explication math√©matique complexe, voici le fonctionnement en langage simple :

1. **Porte d'oubli** (Forget gate) : 
   
    - Comme un tri dans votre rapport : "Quelles informations pass√©es ne sont plus utiles ?"
    - Exemple SIO : Si un nouvel utilisateur se connecte, vous pouvez "oublier" certains d√©tails des sessions pr√©c√©dentes

2. **Porte d'entr√©e** (Input gate) :
   
    - Filtre les nouvelles informations : "Quelles nouvelles informations sont importantes ?"
    - Exemple SIO : Dans un log "Tentative d'acc√®s admin √©chou√©e 5 fois", le nombre de tentatives est plus important que l'heure exacte

3. **Porte de sortie** (Output gate) :
   
    - D√©cide quelles informations partager : "Quelles parties de ma m√©moire sont pertinentes maintenant ?"
    - Exemple SIO : Si vous analysez une faille de s√©curit√©, vous vous concentrez sur les logs d'authentification, pas sur les mises √† jour syst√®me

### Applications pour les √©tudiants BTS SIO

Voici des applications concr√®tes des RNN/LSTM dans votre domaine :

1. **D√©tection d'intrusion r√©seau** :
   
    - Les RNN/LSTM analysent les s√©quences de logs pour d√©tecter des comportements anormaux
    - L'ordre chronologique des √©v√©nements est crucial (d'o√π l'int√©r√™t des RNN)

2. **Pr√©diction de pannes syst√®mes** :
   
    - Les LSTM peuvent analyser les historiques de performance serveur
    - Ils d√©tectent les signes pr√©curseurs de probl√®mes potentiels

3. **Chatbots d'assistance technique** :
   
    - Les RNN/LSTM permettent de comprendre le contexte d'une conversation de support
    - Ils maintiennent la coh√©rence dans les r√©ponses du chatbot d'aide

4. **Analyse de logs de s√©curit√©** :
   
    - Les LSTM peuvent identifier des patterns d'attaque complexes s'√©tendant sur de longues p√©riodes
    - Ils peuvent corr√©ler des √©v√©nements apparemment sans lien

## üî¨ Partie 2: Impl√©mentation d'un LSTM pour l'analyse de sentiment (40 min)

### Instructions

Pour cette partie pratique, vous allez explorer l'analyse de sentiment avec un mod√®le LSTM. Cette activit√© vous permettra de comprendre comment les r√©seaux r√©currents traitent et "comprennent" le texte.

1. Ouvrez le notebook Jupyter [rnn-sequence.ipynb](ressources/rnn-sequence.ipynb) dans Google Colab
2. Suivez les instructions √©tape par √©tape pour impl√©menter un mod√®le LSTM pour l'analyse de sentiment
3. Ex√©cutez chaque cellule et observez les r√©sultats
4. Portez une attention particuli√®re aux sections suivantes :
   
    - Pr√©traitement du texte (tokenisation)
    - Architecture du mod√®le LSTM
    - Visualisation des embeddings de mots
    - Analyse des performances et des erreurs

### Points cl√©s √† explorer

Pendant que vous travaillez sur ce notebook, r√©fl√©chissez aux questions suivantes qui feront l'objet d'une discussion en classe et d'une documentation √† produire :

- **Comment le texte est-il transform√© en entr√©es num√©riques pour le r√©seau ?**
  Observez le processus de tokenisation, la cr√©ation du vocabulaire et la conversion en s√©quences d'indices.

- **Comment les cellules LSTM g√®rent-elles l'information √† long terme ?**
  Analysez l'architecture des cellules LSTM et leur capacit√© √† m√©moriser les informations pertinentes.

- **Quelle est la diff√©rence entre les embeddings de mots positifs et n√©gatifs ?**
  Examinez la visualisation des embeddings et comment les mots de sentiments similaires se regroupent.

- **Comment le mod√®le LSTM peut-il comprendre le contexte d'une phrase ?**
  R√©fl√©chissez √† la mani√®re dont l'ordre des mots et leurs relations sont captur√©s par le mod√®le.

- **Quelles sont les limitations de cette approche pour l'analyse de sentiment ?**
  Identifiez les cas o√π le mod√®le √©choue et pourquoi (ironie, sarcasme, expressions idiomatiques).

- **Comment pourriez-vous am√©liorer ce mod√®le pour des t√¢ches plus complexes ?**
  Proposez des modifications architecturales ou des techniques d'am√©lioration des donn√©es.

### üìã Livrable attendu

√Ä la fin de cette activit√©, vous devrez produire une documentation synth√©tique (1-2 pages) r√©pondant aux questions ci-dessus. Ce document servira de r√©f√©rence pour votre compr√©hension des RNN/LSTM et pourra √™tre int√©gr√© dans la base de connaissances de votre chatbot p√©dagogique.

Un document de r√©f√©rence complet sur ces concepts est disponible [ici](ressources/lstm-sentiment-analyse.md) pour vous aider √† approfondir votre compr√©hension.

## üîÑ Partie 3: Application pratique et test avec Mistral AI (15 min)

### Mise en pratique avec l'API Mistral

Cette derni√®re partie vous permettra de comparer votre mod√®le LSTM avec les capacit√©s d'un grand mod√®le de langage moderne.

1. Utilisez l'API Mistral AI pour r√©aliser des analyses de sentiment sur vos propres phrases test
2. Comparez les r√©sultats obtenus avec ceux de votre mod√®le LSTM
3. Identifiez les diff√©rences en termes de nuances comprises et de pr√©cision

### Points de discussion

- Quelles sont les diff√©rences fondamentales entre un mod√®le LSTM et un LLM comme Mistral ?
- Dans quels cas le LSTM fonctionne-t-il mieux ? Dans quels cas Mistral est-il sup√©rieur ?
- Comment les deux approches pourraient-elles √™tre combin√©es dans un syst√®me r√©el ?

## üìã Fiche d'observations √† compl√©ter

Durant toute cette phase sur les RNN, n'oubliez pas de compl√©ter votre [fiche d'observations](ressources/Partie2-Phase2-fiche-observationsRNN.md) qui sera votre livrable principal pour cette partie du module.

## üìö Conclusion et transition

Cette section sur les r√©seaux r√©currents vous a permis de comprendre une autre architecture fondamentale du Deep Learning, particuli√®rement adapt√©e aux donn√©es s√©quentielles comme le texte ou les s√©ries temporelles. 

Vous avez appris √†:

- Reconna√Ætre les situations o√π les RNN/LSTM sont particuli√®rement adapt√©s
- Comprendre les m√©canismes de m√©moire qui font la force de ces architectures
- Impl√©menter un mod√®le LSTM pour l'analyse de sentiment de texte
- Visualiser et interpr√©ter les repr√©sentations internes du mod√®le

Ces connaissances constitueront une base essentielle pour le d√©veloppement de votre projet de chatbot p√©dagogique dans les prochains modules.

[Retour au Module 2](index.md){ .md-button }
[Continuer vers l'auto-√©valuation](qcm-evaluation-module2.md){ .md-button .md-button--primary }