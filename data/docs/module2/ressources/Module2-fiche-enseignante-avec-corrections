# üìã Fiche Enseignante - Module 2 : Architectures sp√©cialis√©es de r√©seaux de neurones

## Pr√©sentation g√©n√©rale du module

**Dur√©e totale** : 4 heures  
**Public cible** : √âtudiants BTS SIO ayant suivi le Module 1  
**Pr√©requis** : Fondamentaux du Deep Learning (Module 1), bases en Python et TensorFlow/Keras

**Approche p√©dagogique** : Apprentissage par projets pratiques centr√©s sur des architectures sp√©cialis√©es

## Objectifs d'apprentissage

√Ä l'issue de ce module, les √©tudiants seront capables de :
1. Comprendre et impl√©menter des r√©seaux convolutifs (CNN) pour la vision par ordinateur
2. Ma√Ætriser les r√©seaux r√©currents (RNN/LSTM) pour le traitement des s√©quences et du langage
3. Visualiser et interpr√©ter le fonctionnement interne des diff√©rentes architectures
4. Int√©grer ces mod√®les dans des applications concr√®tes
5. Choisir l'architecture adapt√©e selon le type de probl√®me √† r√©soudre

## Organisation du module

### Phase 1 : Mini-projet CNN pour la vision par ordinateur (2h)

#### Objectifs sp√©cifiques
- Comprendre les principes des convolutions et du pooling dans les CNN
- Impl√©menter un CNN pour la classification d'images MNIST
- Visualiser et interpr√©ter les filtres et feature maps
- Int√©grer le mod√®le dans une application web interactive

#### D√©roulement et conseils d'animation

| Dur√©e | Activit√© | Conseils pour l'enseignant |
|-------|----------|----------------------------|
| 30 min | **Principes des CNN**<br>‚Ä¢ D√©couverte guid√©e des convolutions<br>‚Ä¢ Exploration des filtres et feature maps<br>‚Ä¢ Construction du mod√®le mental | ‚Ä¢ Utiliser des analogies visuelles (filtres comme d√©tecteurs de motifs)<br>‚Ä¢ Encourager la r√©flexion sur la hi√©rarchie des caract√©ristiques<br>‚Ä¢ Faire compl√©ter le sch√©ma d'architecture progressivement |
| 50 min | **Impl√©mentation du CNN**<br>‚Ä¢ Travail sur le notebook<br>‚Ä¢ Entra√Ænement et analyse du mod√®le<br>‚Ä¢ Visualisation des caract√©ristiques apprises | ‚Ä¢ S'assurer que tous ont acc√®s √† Colab avec GPU<br>‚Ä¢ Pr√©voir des points d'arr√™t pour v√©rifier la compr√©hension<br>‚Ä¢ Encourager l'exploration des visualisations |
| 40 min | **Application web interactive**<br>‚Ä¢ Cr√©ation de l'interface<br>‚Ä¢ Int√©gration du mod√®le<br>‚Ä¢ Tests avec diff√©rentes entr√©es | ‚Ä¢ Fournir une structure de base pour l'application<br>‚Ä¢ Se concentrer sur l'int√©gration plus que sur le d√©veloppement web<br>‚Ä¢ Encourager la documentation des observations |

#### √âl√©ments de correction pour la Fiche d'observations - CNN

**Tests pratiques avec l'interface**

Un bon taux de r√©ussite se situe g√©n√©ralement autour de :
- Dessin √† la souris : 70-80% (7-8 pr√©dictions correctes sur 10)
- Image import√©e : 60-80% (3-4 pr√©dictions correctes sur 5)

Les variations d√©pendent de la qualit√© des dessins et des images.

**Observations sur les pr√©dictions**

| Question | √âl√©ments de r√©ponse attendus |
|----------|------------------------------|
| Chiffres les mieux reconnus | Chiffres avec structures distinctes : 0, 1, 7 (formes simples et traits nets) |
| Chiffres les plus difficiles | Paires confusion courantes : 3/8, 4/9, 5/6 (structures similaires) |
| Niveau de confiance moyen | ~90% pour les pr√©dictions correctes, ~60-70% pour les incorrectes |

**Architecture du mod√®le**

| Question | √âl√©ments de r√©ponse attendus |
|----------|------------------------------|
| Nombre de couches de convolution | 2 (dans le mod√®le de base) |
| Nombre de couches de pooling | 2 (dans le mod√®le de base) |
| Nombre de couches fully connected | 2 (dense + sortie) |
| Fonction d'activation | ReLU pour les couches interm√©diaires, Softmax pour la couche de sortie |

**Analyse des visualisations**

| Question | √âl√©ments de r√©ponse attendus |
|----------|------------------------------|
| Caract√©ristiques des premi√®res couches | D√©tection de caract√©ristiques de bas niveau : contours, bords, lignes simples orient√©es diff√©remment (horizontales, verticales, diagonales) |
| √âvolution dans les couches profondes | Caract√©ristiques plus abstraites et complexes, combinaison des motifs simples en structures plus √©labor√©es, diminution de la r√©solution spatiale mais augmentation de la profondeur s√©mantique |
| Compr√©hension des erreurs | Les feature maps montrent des activations similaires entre chiffres souvent confondus, certains filtres ne s'activent pas correctement sur des entr√©es ambigu√´s, impact de la r√©solution r√©duite sur les d√©tails fins |

**Points forts de l'application**

R√©ponses pertinentes incluant :
1. Interface intuitive facilitant les tests avec diff√©rentes entr√©es
2. Bonne pr√©cision sur les chiffres clairement √©crits (>70-80%)
3. Temps de r√©ponse rapide pour les pr√©dictions
4. Visualisation des feature maps aidant √† comprendre le fonctionnement
5. Robustesse relative aux variations mineures d'√©criture

**Limitations observ√©es**

R√©ponses pertinentes incluant :
1. Sensibilit√© √† l'√©paisseur des traits et au positionnement
2. Difficult√© avec les styles d'√©criture diff√©rents des donn√©es d'entra√Ænement
3. Confusion entre chiffres visuellement similaires
4. Performance r√©duite sur les chiffres mal centr√©s ou de taille inappropri√©e
5. Mod√®le entra√Æn√© uniquement sur MNIST, limitant la g√©n√©ralisation

**Concept des convolutions**

Une bonne r√©ponse devrait inclure :
- Description de la convolution comme op√©ration de filtrage local
- Explication du partage de poids et de la d√©tection de caract√©ristiques ind√©pendamment de leur position
- Avantages par rapport aux r√©seaux fully connected (moins de param√®tres, meilleure g√©n√©ralisation)
- Explication de l'extraction hi√©rarchique des caract√©ristiques
- R√©f√©rence √† l'inspiration biologique (champ r√©ceptif du syst√®me visuel)

**Concept du pooling**

Une bonne r√©ponse devrait inclure :
- D√©finition du pooling comme m√©thode de sous-√©chantillonnage
- Explication de la r√©duction de dimensionnalit√© et des avantages computationnels
- Mention de l'invariance aux petites translations/d√©formations
- Distinction entre Max-Pooling et Average-Pooling
- Explication du r√¥le dans la hi√©rarchie des caract√©ristiques

**Transfer learning**

Une bonne r√©ponse devrait inclure :
- D√©finition correcte du transfer learning (r√©utilisation d'un mod√®le pr√©-entra√Æn√©)
- Suggestion d'utiliser un mod√®le plus large pr√©-entra√Æn√© sur ImageNet
- Explication du gel des couches de base et r√©entra√Ænement des couches sup√©rieures
- Mention des avantages (moins de donn√©es n√©cessaires, convergence plus rapide)
- Adaptations n√©cessaires pour les images de chiffres

### Phase 2 : Mini-projet RNN pour le traitement du langage (1h30)

#### Objectifs sp√©cifiques
- Comprendre les principes des r√©seaux r√©currents et des cellules LSTM
- Impl√©menter un mod√®le LSTM pour l'analyse de sentiment
- Visualiser et interpr√©ter les embeddings de mots
- Explorer les capacit√©s de compr√©hension contextuelle des RNN

#### D√©roulement et conseils d'animation

| Dur√©e | Activit√© | Conseils pour l'enseignant |
|-------|----------|----------------------------|
| 20 min | **Principes des RNN/LSTM**<br>‚Ä¢ Pr√©sentation interactive des concepts<br>‚Ä¢ Analogies et cas d'usage<br>‚Ä¢ Discussion sur les probl√®mes r√©solus | ‚Ä¢ Utiliser l'analogie du "carnet de notes" pour expliquer la m√©moire<br>‚Ä¢ Clarifier les diff√©rentes portes des LSTM avec des exemples concrets<br>‚Ä¢ Faire des liens avec les applications BTS SIO (logs, textes) |
| 40 min | **Impl√©mentation LSTM pour sentiment**<br>‚Ä¢ Travail sur le notebook RNN<br>‚Ä¢ Pr√©traitement du texte<br>‚Ä¢ Entra√Ænement et √©valuation | ‚Ä¢ Expliquer clairement les √©tapes de pr√©traitement du texte<br>‚Ä¢ Mettre en √©vidence les diff√©rences avec le pr√©traitement d'images<br>‚Ä¢ Guider l'analyse des r√©sultats d'entra√Ænement |
| 20 min | **Analyse des embeddings**<br>‚Ä¢ Visualisation des vecteurs de mots<br>‚Ä¢ Exploration des clusters s√©mantiques<br>‚Ä¢ Compr√©hension des relations | ‚Ä¢ Encourager l'exploration des relations entre mots<br>‚Ä¢ Faire remarquer les clusters de polarit√© (positif/n√©gatif)<br>‚Ä¢ Discuter des implications pour la compr√©hension du langage |
| 10 min | **Documentation et r√©flexion**<br>‚Ä¢ Compl√©tion de la fiche d'observations<br>‚Ä¢ Comparaison avec l'approche CNN | ‚Ä¢ Stimuler la r√©flexion comparative entre CNN et RNN<br>‚Ä¢ Encourager l'identification des cas d'usage adapt√©s<br>‚Ä¢ Faire le lien avec le projet final de chatbot |

#### √âl√©ments de correction pour la Fiche d'observations - RNN

**Concepts fondamentaux**

| Question | √âl√©ments de r√©ponse attendus |
|----------|------------------------------|
| Diff√©rence entre RNN et r√©seaux classiques | Les RNN poss√®dent des connexions r√©currentes formant des boucles, permettant de conserver et utiliser les informations des √©tapes pr√©c√©dentes, contrairement aux r√©seaux feedforward o√π l'information circule uniquement dans une direction |
| Int√©r√™t des RNN pour le texte | Capacit√© √† conserver le contexte et l'ordre des mots, permettant de capturer les d√©pendances √† long terme et le sens s√©quentiel inh√©rent au langage |

**M√©canisme de m√©moire LSTM**

| √âl√©ment | Fonction principale attendue |
|---------|------------------------------|
| Porte d'oubli | D√©termine quelles informations de l'√©tat pr√©c√©dent doivent √™tre conserv√©es ou supprim√©es |
| Porte d'entr√©e | Contr√¥le quelles nouvelles informations seront ajout√©es √† l'√©tat de la cellule |
| Porte de sortie | D√©termine quelle partie de l'√©tat de la cellule sera transmise √† la sortie |
| Cellule de m√©moire | Stocke l'information √† long terme, prot√©g√©e par les m√©canismes de portes |

Pour la r√©solution du probl√®me du gradient qui s'√©vanouit : Les LSTM utilisent un chemin direct pour la propagation du gradient √† travers leur cellule de m√©moire, et les portes contr√¥lent quelles informations sont conserv√©es ou mises √† jour, permettant aux gradients de circuler sur de longues s√©quences sans s'√©vanouir.

**Pr√©paration des donn√©es textuelles**

Les √©tapes de pr√©traitement attendues incluent :
1. Nettoyage du texte (suppression ponctuation, conversion minuscules)
2. Tokenisation (d√©coupage en mots/tokens)
3. Cr√©ation d'un vocabulaire avec indices uniques
4. Conversion en s√©quences num√©riques (remplacement des mots par indices)
5. Padding des s√©quences pour uniformiser leur longueur

**Diff√©rences avec le pr√©traitement d'images** :
- Images : normalisation des valeurs de pixels, redimensionnement, augmentation
- Texte : tokenisation, gestion des s√©quences de longueur variable, embeddings

**Visualisation des embeddings**

Observations attendues sur les clusters :
- Formation de groupes distincts de mots positifs et n√©gatifs
- Proximit√© s√©mantique entre mots de sens similaire
- Organisation refl√©tant les nuances d'intensit√© (ex: "bon", "excellent", "extraordinaire")

**Compr√©hension contextuelle**

| Type de phrase | Exemple pertinent | Explication |
|----------------|-------------------|-------------|
| N√©gation | "Ce film n'est pas mauvais" | Le mod√®le doit comprendre que "pas mauvais" est positif |
| Contraste | "Malgr√© des d√©fauts, excellent film" | Capacit√© √† donner plus de poids √† certains √©l√©ments |
| Ironie | "Quelle performance incroyable ! J'ai dormi" | Difficult√© pour le mod√®le √† d√©tecter le sarcasme |

**Comparaison LSTM vs approches simples**

| Aspect | LSTM (r√©ponse attendue) | Bag-of-Words (r√©ponse attendue) |
|--------|-------------------------|----------------------------------|
| Compr√©hension du contexte | Bonne, maintient l'ordre et le contexte des mots | Faible, ignore l'ordre des mots |
| Gestion des n√©gations | Peut capturer les n√©gations et leur impact | Tr√®s limit√©e, consid√®re "pas bon" comme n√©gatif |
| D√©tection des nuances | Mod√©r√©e √† bonne selon l'entra√Ænement | Faible, bas√©e uniquement sur les mots pr√©sents |
| Vitesse de traitement | Plus lente, traitement s√©quentiel | Plus rapide, traitement parall√©lisable |
| Besoin en donn√©es | Important, n√©cessite de grands corpus | Mod√©r√©, peut fonctionner avec moins de donn√©es |

**Limites observ√©es**

Principales limitations √† identifier :
1. Difficult√© √† d√©tecter le sarcasme et l'ironie
2. Sensibilit√© au manque de contexte culturel
3. Probl√®mes avec les expressions idiomatiques
4. N√©cessit√© de grands corpus d'entra√Ænement
5. Temps d'entra√Ænement relativement long

**Applications potentielles**

Applications professionnelles pertinentes :
1. Analyse des sentiments des clients pour le service client
2. Mod√©ration automatique de contenus sur les plateformes sociales
3. Analyse pr√©dictive bas√©e sur des documents textuels
4. Assistants virtuels et chatbots pour le support technique
5. Classification automatique des emails et tickets d'assistance

### Phase 3 : Auto-√©valuation et synth√®se (30 min)

#### Objectifs sp√©cifiques
- √âvaluer la compr√©hension des diff√©rentes architectures
- Comparer les forces et faiblesses des CNN et RNN
- R√©fl√©chir aux applications potentielles dans le contexte BTS SIO

#### D√©roulement et conseils d'animation

| Dur√©e | Activit√© | Conseils pour l'enseignant |
|-------|----------|----------------------------|
| 15 min | **QCM d'√©valuation**<br>‚Ä¢ R√©alisation du QCM<br>‚Ä¢ V√©rification des r√©ponses<br>‚Ä¢ Analyse des erreurs | ‚Ä¢ Pr√©ciser que le QCM est formatif, non not√©<br>‚Ä¢ Encourager l'auto-correction<br>‚Ä¢ Clarifier les points mal compris |
| 10 min | **Synth√®se architectures**<br>‚Ä¢ Tableau comparatif CNN/RNN<br>‚Ä¢ Crit√®res de choix<br>‚Ä¢ Applications types | ‚Ä¢ Impliquer les √©tudiants dans la construction du tableau<br>‚Ä¢ Faire le lien avec les cas d'usage professionnels<br>‚Ä¢ Situer ces architectures dans l'√©volution du DL |
| 5 min | **Transition vers le module 3**<br>‚Ä¢ Aper√ßu des frameworks<br>‚Ä¢ Lien avec le projet final<br>‚Ä¢ Questions ouvertes | ‚Ä¢ Faire le pont avec les applications pratiques √† venir<br>‚Ä¢ Montrer l'importance de ces architectures pour le chatbot<br>‚Ä¢ Recueillir les questions pour le module suivant |

#### √âl√©ments de correction pour le QCM d'√©valuation

Voir le corrig√© fourni dans le document `qcm-evaluation-module2.md`. Les points cl√©s √† souligner :

- Question 2b : Les filtres (kernels) sont des matrices de poids qui s'appliquent localement sur les donn√©es d'entr√©e.
- Question 3b : Le pooling r√©duit la dimensionnalit√© tout en pr√©servant les informations importantes.
- Question 4 : Avantages des CNN (partage des param√®tres, invariance √† la translation, r√©duction du nombre de param√®tres).
- Question 7c : Dans un CNN, les caract√©ristiques deviennent de plus en plus abstraites et complexes.
- Question 8b : Les RNN contiennent des connexions formant des boucles permettant de m√©moriser les informations.
- Question 10c : Probl√®me de disparition ou d'explosion du gradient dans les RNN classiques.
- Question 11b : Les LSTM poss√®dent des m√©canismes de portes contr√¥lant le flux d'information.
- Question 12a : La "porte d'oubli" d√©termine quelles informations de l'√©tat pr√©c√©dent doivent √™tre conserv√©es ou supprim√©es.

## √âvaluation et suivi

### Livrables √† r√©cup√©rer
- Fiche d'observations Phase 1 : "Mini-projet CNN pour la vision par ordinateur"
- Fiche d'observations Phase 2 : "Mini-projet RNN pour le traitement du langage"
- Mod√®le CNN fonctionnel pour la classification d'images
- Mod√®le LSTM pour l'analyse de sentiment textuel

### Crit√®res d'√©valuation

| Crit√®re | Indicateurs de r√©ussite |
|---------|------------------------|
| **Compr√©hension des architectures** | ‚Ä¢ Explication correcte des convolutions/pooling<br>‚Ä¢ Compr√©hension du fonctionnement des cellules LSTM |
| **Impl√©mentation technique** | ‚Ä¢ Mod√®les CNN et RNN fonctionnels<br>‚Ä¢ Adaptation des hyperparam√®tres |
| **Analyse des visualisations** | ‚Ä¢ Interpr√©tation pertinente des feature maps<br>‚Ä¢ Analyse des embeddings de mots |
| **Comparaison critique** | ‚Ä¢ Identification des forces/faiblesses de chaque architecture<br>‚Ä¢ Choix justifi√© selon les types de donn√©es |

### Bar√®me sugg√©r√© (sur 20 points)

| Livrable | Points | √âl√©ments √©valu√©s |
|----------|--------|------------------|
| Fiche CNN | 8 pts | ‚Ä¢ Tests pratiques (2 pts)<br>‚Ä¢ Analyse des visualisations (3 pts)<br>‚Ä¢ Compr√©hension des concepts (3 pts) |
| Fiche RNN | 8 pts | ‚Ä¢ Pr√©traitement et architecture (3 pts)<br>‚Ä¢ Analyse des embeddings (3 pts)<br>‚Ä¢ Limites et applications (2 pts) |
| Mod√®les fonctionnels | 4 pts | ‚Ä¢ Fonctionnalit√© du CNN (2 pts)<br>‚Ä¢ Fonctionnalit√© du LSTM (2 pts) |

## Ressources et mat√©riel

### Pour l'enseignant
- Pr√©sentations visuelles des architectures CNN et RNN
- Solutions compl√®tes des notebooks
- Exemples pr√©par√©s d'images et de textes pour les tests
- Mod√®les pr√©-entra√Æn√©s en cas de probl√®me

### Pour les √©tudiants
- Notebooks pr√©-configur√©s pour CNN et RNN
- Fiches d'observations √† compl√©ter
- Datasets pr√©par√©s (MNIST, dataset de sentiment)
- Guide de visualisation des CNN et des embeddings

## Adaptations possibles

### Pour les √©tudiants avanc√©s
- Proposer l'impl√©mentation d'architectures plus complexes (ResNet, BiLSTM)
- Sugg√©rer l'exploration de l'API Mistral pour comparer avec le mod√®le LSTM
- Encourager l'int√©gration des deux types de mod√®les dans une application unique

### Pour les √©tudiants en difficult√©
- Fournir des mod√®les pr√©-entrain√©s √† analyser plut√¥t qu'√† construire
- Simplifier l'architecture √† impl√©menter
- Proposer des guides √©tape par √©tape plus d√©taill√©s

## Points de vigilance et conseils

### Difficult√©s techniques courantes
- Temps d'entra√Ænement trop long ‚Üí Utiliser des sous-ensembles des donn√©es
- Probl√®mes de m√©moire GPU ‚Üí R√©duire la taille des batchs ou du mod√®le
- Erreurs dans les dimensions des tenseurs ‚Üí Pr√©voir des checkpoints de d√©bogage

### Difficult√©s conceptuelles courantes
- Confusion entre les types de couches ‚Üí Utiliser des visualisations et analogies
- Difficult√© √† comprendre les cellules LSTM ‚Üí Simplifier avec des diagrammes de flux
- Incompr√©hension des embeddings ‚Üí Utiliser des analogies spatiales (mots comme points dans l'espace)

### Gestion du temps
- La phase CNN peut facilement d√©border ‚Üí Pr√©voir une version simplifi√©e au besoin
- Le pr√©traitement de texte prend souvent plus de temps que pr√©vu ‚Üí Avoir des checkpoints

## Prolongements possibles

- Exploration des architectures hybrides (CNN+RNN pour la vid√©o)
- Introduction aux mod√®les pr√©-entra√Æn√©s (VGG, BERT)
- Applications aux donn√©es sp√©cifiques BTS SIO (logs, codes, documentation)

---

## Annexe : Concepts cl√©s √† aborder

### CNN - Concepts essentiels
- Convolution et filtres
- Pooling et sous-√©chantillonnage
- Feature maps et visualisation
- Hi√©rarchie des caract√©ristiques
- Flatten et couches fully connected
- Transfer learning

### RNN - Concepts essentiels
- S√©quentialit√© et √©tats cach√©s
- Probl√®me du gradient qui s'√©vanouit
- Cellules LSTM et leurs composants
- Embeddings de mots
- Bidirectionnalit√©
- Traitement de s√©quences de longueur variable

### Comparaison architecturale
- Types de donn√©es adapt√©es √† chaque architecture
- Complexit√© computationnelle
- Besoins en donn√©es d'entra√Ænement
- Facilit√© d'interpr√©tation
- Applications types

## Annexe : FAQ anticip√©es

**Q: Pourquoi utiliser des CNN plut√¥t que des r√©seaux denses pour les images ?**  
R: Les CNN exploitent la structure spatiale des images gr√¢ce au partage des poids et √† l'invariance √† la translation. Ils n√©cessitent beaucoup moins de param√®tres et sont plus efficaces pour d√©tecter des motifs visuels.

**Q: Pourquoi les RNN classiques ont-ils des difficult√©s avec les longues s√©quences ?**  
R: √Ä cause du probl√®me du gradient qui s'√©vanouit, o√π l'information des premiers √©l√©ments se dilue progressivement lors de la backpropagation sur de longues s√©quences.

**Q: Comment choisir entre un CNN et un RNN pour un probl√®me donn√© ?**  
R: D√©pend de la nature des donn√©es : si la structure spatiale est importante (images, donn√©es en grille), utilisez un CNN. Si l'ordre s√©quentiel et le contexte temporel sont cruciaux (texte, s√©ries temporelles), privil√©giez un RNN/LSTM.

**Q: Pourquoi les embeddings sont-ils importants pour le NLP ?**  
R: Ils transforment des mots en vecteurs denses qui capturent les relations s√©mantiques, permettant au r√©seau de g√©n√©raliser sur des mots similaires et de comprendre les nuances du langage.

**Q: Comment ces architectures s'int√®grent-elles dans le d√©veloppement du chatbot ?**  
R: Le chatbot utilisera des principes similaires aux RNN/LSTM pour la compr√©hension et g√©n√©ration de texte. Les embeddings seront essentiels pour capturer le sens des mots et des phrases.