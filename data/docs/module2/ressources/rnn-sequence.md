# RNN/LSTM pour l'analyse de sentiment - Notebook complet

Ce notebook vous guide dans la crÃ©ation d'un modÃ¨le LSTM pour analyser le sentiment de textes (positif/nÃ©gatif).

## Cellule 1 (Markdown) - Introduction

```markdown
# ğŸ§  RNN/LSTM pour l'analyse de sentiment

## DÃ©couverte des rÃ©seaux rÃ©currents avec un cas concret

Dans ce notebook, vous allez :
- âœ… Comprendre comment les RNN traitent les sÃ©quences de texte
- âœ… CrÃ©er un modÃ¨le LSTM pour analyser le sentiment
- âœ… Visualiser les embeddings de mots
- âœ… Tester le modÃ¨le sur vos propres phrases

**DurÃ©e estimÃ©e** : 50 minutes

**Cas d'usage** : Analyser automatiquement les avis clients, commentaires, etc.
```

## Cellule 2 (Code) - Configuration et imports

```python
# Imports nÃ©cessaires
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing import sequence
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
import pandas as pd

# Configuration
print(f"TensorFlow version: {tf.__version__}")
print("GPU disponible:", "Oui" if tf.config.list_physical_devices('GPU') else "Non")

# ParamÃ¨tres du modÃ¨le
MAX_FEATURES = 5000  # Nombre de mots dans le vocabulaire
MAX_LEN = 200       # Longueur maximale des sÃ©quences
EMBEDDING_SIZE = 128 # Taille des embeddings

print("\nâœ… Configuration terminÃ©e !")
```

## Cellule 3 (Code) - Chargement et exploration des donnÃ©es

```python
# Chargement du dataset IMDB (avis de films)
print("ğŸ“¥ Chargement du dataset IMDB...")
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)

print(f"ğŸ“Š DonnÃ©es d'entraÃ®nement : {len(X_train)} avis")
print(f"ğŸ“Š DonnÃ©es de test : {len(X_test)} avis")
print(f"ğŸ“Š Vocabulaire : {MAX_FEATURES} mots les plus frÃ©quents")

# RÃ©cupÃ©ration du dictionnaire de mots
word_index = imdb.get_word_index()
reverse_word_index = {v: k for k, v in word_index.items()}
reverse_word_index[0] = '<PAD>'
reverse_word_index[1] = '<START>'
reverse_word_index[2] = '<UNKNOWN>'

def decode_review(encoded_review):
    """Convertit une sÃ©quence d'indices en texte lisible"""
    return ' '.join([reverse_word_index.get(i, '<UNKNOWN>') for i in encoded_review])

# Affichage de quelques exemples
print("\nğŸ“ Exemples d'avis (avant preprocessing) :")
for i in range(3):
    sentiment = "ğŸ˜Š POSITIF" if y_train[i] == 1 else "ğŸ˜ NÃ‰GATIF"
    print(f"\n{sentiment} - Longueur: {len(X_train[i])} mots")
    decoded = decode_review(X_train[i])
    # Afficher seulement les premiers mots pour la lisibilitÃ©
    print(f"Texte: {decoded[:200]}...")

# Distribution des longueurs
lengths = [len(x) for x in X_train]
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.hist(lengths, bins=50, alpha=0.7)
plt.title('Distribution des longueurs d\'avis')
plt.xlabel('Nombre de mots')
plt.ylabel('FrÃ©quence')
plt.axvline(MAX_LEN, color='red', linestyle='--', label=f'Limite fixÃ©e: {MAX_LEN}')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(y_train, bins=2, alpha=0.7, color=['red', 'green'])
plt.title('Distribution des sentiments')
plt.xlabel('Sentiment (0=NÃ©gatif, 1=Positif)')
plt.ylabel('Nombre d\'avis')
plt.xticks([0, 1], ['NÃ©gatif', 'Positif'])

plt.tight_layout()
plt.show()

print(f"\nğŸ“Š Statistiques des longueurs :")
print(f"   - Longueur moyenne : {np.mean(lengths):.1f} mots")
print(f"   - Longueur mÃ©diane : {np.median(lengths):.1f} mots")
print(f"   - Avis > {MAX_LEN} mots : {np.sum(np.array(lengths) > MAX_LEN)}")
```

## Cellule 4 (Code) - PrÃ©paration des donnÃ©es

```python
# Padding des sÃ©quences (toutes Ã  la mÃªme longueur)
print("ğŸ”§ PrÃ©paration des donnÃ©es...")
print(f"   - Troncature/padding Ã  {MAX_LEN} mots")

X_train = sequence.pad_sequences(X_train, maxlen=MAX_LEN, padding='post')
X_test = sequence.pad_sequences(X_test, maxlen=MAX_LEN, padding='post')

print(f"   - Forme finale X_train : {X_train.shape}")
print(f"   - Forme finale X_test : {X_test.shape}")

# Visualisation de l'effet du padding
exemple_idx = 0
print(f"\nğŸ“ Exemple de preprocessing :")
print(f"   - Avis original : {len([x for x in X_train[exemple_idx] if x != 0])} mots utiles")
print(f"   - AprÃ¨s padding : {X_train.shape[1]} positions")
print(f"   - PremiÃ¨res valeurs : {X_train[exemple_idx][:20]}")
print(f"   - (0 = padding, autres = indices de mots)")

# Conversion en format appropriÃ© pour TensorFlow
X_train = X_train.astype('int32')
X_test = X_test.astype('int32')
y_train = y_train.astype('int32') 
y_test = y_test.astype('int32')

print("\nâœ… DonnÃ©es prÃ©parÃ©es pour l'entraÃ®nement !")
```

## Cellule 5 (Code) - Construction du modÃ¨le LSTM

```python
# Construction du modÃ¨le LSTM
print("ğŸ—ï¸ Construction du modÃ¨le LSTM...")

model = Sequential([
    # Couche d'embedding : convertit les indices en vecteurs denses
    Embedding(
        input_dim=MAX_FEATURES,    # Taille du vocabulaire
        output_dim=EMBEDDING_SIZE, # Dimension des embeddings
        input_length=MAX_LEN,      # Longueur des sÃ©quences
        name='embedding'
    ),
    
    # Couche LSTM : traite les sÃ©quences
    LSTM(
        units=64,           # Nombre d'unitÃ©s LSTM
        dropout=0.2,        # Dropout sur les entrÃ©es
        recurrent_dropout=0.2,  # Dropout sur les connexions rÃ©currentes
        name='lstm'
    ),
    
    # Couche de rÃ©gularisation
    Dropout(0.5, name='dropout'),
    
    # Couche de sortie : classification binaire
    Dense(1, activation='sigmoid', name='output')
])

# Compilation du modÃ¨le
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Affichage de l'architecture
print("\nğŸ“‹ Architecture du modÃ¨le :")
model.summary()

print(f"\nğŸ”¢ DÃ©tails des couches :")
print(f"   - Embedding : {MAX_FEATURES} mots â†’ {EMBEDDING_SIZE} dimensions")
print(f"   - LSTM : 64 unitÃ©s avec mÃ©moire sÃ©quentielle")
print(f"   - Dense : 1 neurone pour classification binaire (0-1)")
print(f"   - Total paramÃ¨tres : {model.count_params():,}")
```

## Cellule 6 (Code) - EntraÃ®nement du modÃ¨le

```python
# EntraÃ®nement du modÃ¨le
print("ğŸš€ DÃ©but de l'entraÃ®nement...")
print("â±ï¸ Les LSTM sont plus lents que les CNN, patience !")

# EntraÃ®nement avec validation
history = model.fit(
    X_train, y_train,
    batch_size=128,
    epochs=3,  # Peu d'Ã©poques pour la dÃ©monstration
    validation_split=0.2,
    verbose=1
)

# Ã‰valuation finale
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"\nğŸ“Š RÃ©sultats finaux :")
print(f"   - PrÃ©cision sur test : {test_accuracy*100:.2f}%")
print(f"   - Perte sur test : {test_loss:.4f}")

# Visualisation des courbes d'apprentissage
plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], 'b-', label='EntraÃ®nement', linewidth=2)
plt.plot(history.history['val_accuracy'], 'r-', label='Validation', linewidth=2)
plt.title('Ã‰volution de la prÃ©cision')
plt.xlabel('Ã‰poque')
plt.ylabel('PrÃ©cision')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], 'b-', label='EntraÃ®nement', linewidth=2)
plt.plot(history.history['val_loss'], 'r-', label='Validation', linewidth=2)
plt.title('Ã‰volution de la perte')
plt.xlabel('Ã‰poque')
plt.ylabel('Perte')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\nâœ… EntraÃ®nement terminÃ© !")
```

## Cellule 7 (Code) - Test et prÃ©dictions

```python
# Test du modÃ¨le sur quelques exemples
print("ğŸ” Test du modÃ¨le sur des exemples...")

# SÃ©lection d'exemples
indices = np.random.choice(len(X_test), 8, replace=False)
test_examples = X_test[indices]
true_labels = y_test[indices]

# PrÃ©dictions
predictions = model.predict(test_examples, verbose=0)
predicted_probs = predictions.flatten()
predicted_labels = (predicted_probs > 0.5).astype(int)

# Affichage des rÃ©sultats
print("\nğŸ“ Exemples de prÃ©dictions :")
for i in range(8):
    true_sentiment = "ğŸ˜Š POSITIF" if true_labels[i] == 1 else "ğŸ˜ NÃ‰GATIF"
    pred_sentiment = "ğŸ˜Š POSITIF" if predicted_labels[i] == 1 else "ğŸ˜ NÃ‰GATIF"
    confidence = predicted_probs[i] if predicted_labels[i] == 1 else 1 - predicted_probs[i]
    correct = "âœ…" if true_labels[i] == predicted_labels[i] else "âŒ"
    
    print(f"\n{correct} Exemple {i+1}:")
    print(f"   RÃ©el: {true_sentiment} | PrÃ©dit: {pred_sentiment} | Confiance: {confidence:.1%}")
    
    # DÃ©coder quelques mots du texte
    decoded_text = decode_review(test_examples[i])
    # Afficher les premiers mots (sans les balises techniques)
    clean_text = decoded_text.replace('<START>', '').replace('<PAD>', '').strip()
    words = clean_text.split()[:15]  # Premiers 15 mots
    print(f"   Texte: {' '.join(words)}...")

# Matrice de confusion simple
from sklearn.metrics import confusion_matrix, classification_report

y_pred_all = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()

print(f"\nğŸ“Š Performance globale sur l'ensemble de test :")
print(f"   - PrÃ©cision : {test_accuracy:.1%}")
print(f"   - Exemples corrects : {np.sum(y_test == y_pred_all)}/{len(y_test)}")

# Matrice de confusion
cm = confusion_matrix(y_test, y_pred_all)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['NÃ©gatif', 'Positif'], 
            yticklabels=['NÃ©gatif', 'Positif'])
plt.title('Matrice de confusion')
plt.xlabel('PrÃ©dictions')
plt.ylabel('RÃ©alitÃ©')
plt.show()

print(f"\nRapport de classification :")
print(classification_report(y_test, y_pred_all, target_names=['NÃ©gatif', 'Positif']))
```

## Cellule 8 (Code) - Visualisation des embeddings de mots

```python
# Extraction et visualisation des embeddings
print("ğŸ¨ Visualisation des embeddings de mots...")

# RÃ©cupÃ©ration de la couche d'embedding
embedding_layer = model.get_layer('embedding')
embeddings = embedding_layer.get_weights()[0]  # Matrice des embeddings

print(f"ğŸ“Š Dimensions des embeddings : {embeddings.shape}")
print(f"   - {embeddings.shape[0]} mots dans le vocabulaire")
print(f"   - {embeddings.shape[1]} dimensions par mot")

# SÃ©lection de mots intÃ©ressants pour la visualisation
interesting_words = [
    'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic',  # Mots positifs
    'bad', 'terrible', 'awful', 'horrible', 'worst', 'hate',           # Mots nÃ©gatifs
    'movie', 'film', 'story', 'actor', 'acting', 'director',          # Mots neutres/contexte
    'boring', 'interesting', 'funny', 'dramatic', 'beautiful'         # Mots descriptifs
]

# RÃ©cupÃ©ration des indices et embeddings de ces mots
word_indices = []
word_labels = []
for word in interesting_words:
    if word in word_index and word_index[word] < MAX_FEATURES:
        idx = word_index[word]
        word_indices.append(idx)
        word_labels.append(word)

selected_embeddings = embeddings[word_indices]

print(f"\nğŸ” Mots sÃ©lectionnÃ©s pour visualisation : {len(word_labels)}")

# RÃ©duction de dimension avec t-SNE
print("ğŸ”„ RÃ©duction de dimension en cours (t-SNE)...")
tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(word_labels)-1))
embeddings_2d = tsne.fit_transform(selected_embeddings)

# Visualisation
plt.figure(figsize=(14, 10))

# Coloration par type de mot
colors = []
for word in word_labels:
    if word in ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic']:
        colors.append('green')
    elif word in ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate']:
        colors.append('red')
    elif word in ['movie', 'film', 'story', 'actor', 'acting', 'director']:
        colors.append('blue')
    else:
        colors.append('orange')

scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], 
                     c=colors, s=100, alpha=0.7)

# Ajout des labels
for i, word in enumerate(word_labels):
    plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]), 
                xytext=(5, 5), textcoords='offset points', 
                fontsize=12, fontweight='bold')

plt.title('Visualisation des embeddings de mots\n' + 
          'Vert: Positif | Rouge: NÃ©gatif | Bleu: Contexte | Orange: Descriptif', 
          fontsize=14)
plt.xlabel('Dimension t-SNE 1')
plt.ylabel('Dimension t-SNE 2')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(f"\nğŸ’¡ Observations attendues :")
print(f"   - Les mots positifs (verts) se regroupent ensemble")
print(f"   - Les mots nÃ©gatifs (rouges) forment un autre cluster")
print(f"   - Les mots de contexte (bleus) sont plus dispersÃ©s")
print(f"   - Plus les mots sont proches, plus ils sont sÃ©mantiquement similaires")
```

## Cellule 9 (Code) - Test avec vos propres phrases

```python
# Fonction pour tester des phrases personnalisÃ©es
def predict_sentiment(text, model, word_index, max_features=MAX_FEATURES, max_len=MAX_LEN):
    """
    PrÃ©dit le sentiment d'un texte personnalisÃ©
    """
    # PrÃ©traitement du texte
    words = text.lower().split()
    
    # Conversion en indices
    sequence = []
    for word in words:
        if word in word_index and word_index[word] < max_features:
            sequence.append(word_index[word])
        else:
            sequence.append(2)  # <UNKNOWN>
    
    # Padding
    if len(sequence) < max_len:
        sequence = sequence + [0] * (max_len - len(sequence))
    else:
        sequence = sequence[:max_len]
    
    # PrÃ©diction
    sequence = np.array([sequence])
    prediction = model.predict(sequence, verbose=0)[0][0]
    
    sentiment = "ğŸ˜Š POSITIF" if prediction > 0.5 else "ğŸ˜ NÃ‰GATIF"
    confidence = prediction if prediction > 0.5 else 1 - prediction
    
    return sentiment, confidence, prediction

# Test avec des phrases d'exemple
print("ğŸ§ª Test avec des phrases personnalisÃ©es :")

test_sentences = [
    "This movie is absolutely fantastic and amazing",
    "I hated this film it was terrible and boring",
    "The movie was okay nothing special",
    "Best movie I have ever seen in my life",
    "Worst acting and stupid story",
    "The cinematography was beautiful but the story was confusing",
    "Not bad but could be better",
    "This film changed my life incredible experience"
]

print("\nğŸ“± RÃ©sultats des tests :")
for i, sentence in enumerate(test_sentences, 1):
    sentiment, confidence, raw_score = predict_sentiment(sentence, model, word_index)
    print(f"\n{i}. \"{sentence}\"")
    print(f"   â†’ {sentiment} (confiance: {confidence:.1%}, score brut: {raw_score:.3f})")

# Test interactif (optionnel)
print(f"\nğŸ¯ Testez vos propres phrases !")
print(f"ğŸ’¡ Tapez 'quit' pour terminer")

while True:
    try:
        user_input = input("\nâœï¸  Entrez une phrase en anglais : ")
        if user_input.lower() == 'quit':
            break
        
        sentiment, confidence, raw_score = predict_sentiment(user_input, model, word_index)
        print(f"ğŸ“Š RÃ©sultat : {sentiment} (confiance: {confidence:.1%})")
        
        # Analyse des mots
        words = user_input.lower().split()
        print(f"ğŸ” Mots analysÃ©s : {len(words)} mots")
        unknown_words = [w for w in words if w not in word_index or word_index[w] >= MAX_FEATURES]
        if unknown_words:
            print(f"â“ Mots inconnus du modÃ¨le : {', '.join(unknown_words[:5])}")
    
    except KeyboardInterrupt:
        break
    except Exception as e:
        print(f"âŒ Erreur : {e}")

print("\nâœ… Tests terminÃ©s !")
```

## Cellule 10 (Code) - Analyse des limites et erreurs

```python
# Analyse des erreurs du modÃ¨le
print("ğŸ” Analyse des erreurs et limites du modÃ¨le...")

# Trouver des exemples mal classifiÃ©s
y_pred_proba = model.predict(X_test, verbose=0).flatten()
y_pred = (y_pred_proba > 0.5).astype(int)

# Indices des erreurs
wrong_predictions = np.where(y_test != y_pred)[0]

print(f"ğŸ“Š Statistiques d'erreurs :")
print(f"   - Erreurs totales : {len(wrong_predictions)}/{len(y_test)} ({len(wrong_predictions)/len(y_test):.1%})")

# Analyser les types d'erreurs
false_positives = np.where((y_test == 0) & (y_pred == 1))[0]  # PrÃ©dit positif alors que c'est nÃ©gatif
false_negatives = np.where((y_test == 1) & (y_pred == 0))[0]  # PrÃ©dit nÃ©gatif alors que c'est positif

print(f"   - Faux positifs : {len(false_positives)} (nÃ©gatifs classÃ©s comme positifs)")
print(f"   - Faux nÃ©gatifs : {len(false_negatives)} (positifs classÃ©s comme nÃ©gatifs)")

# Examiner quelques erreurs intÃ©ressantes
print(f"\nğŸ” Exemples d'erreurs intÃ©ressantes :")

# Faux positifs avec haute confiance
if len(false_positives) > 0:
    fp_confident = false_positives[np.argsort(y_pred_proba[false_positives])[-3:]]  # Top 3 plus confiants
    print(f"\nâŒ Faux positifs (nÃ©gatifs prÃ©dits comme positifs) :")
    for i, idx in enumerate(fp_confident):
        print(f"\n{i+1}. Confiance: {y_pred_proba[idx]:.1%}")
        decoded = decode_review(X_test[idx])
        clean_text = decoded.replace('<START>', '').replace('<PAD>', '').strip()
        words = clean_text.split()[:25]
        print(f"   Texte: {' '.join(words)}...")

# Faux nÃ©gatifs avec haute confiance
if len(false_negatives) > 0:
    fn_confident = false_negatives[np.argsort(y_pred_proba[false_negatives])[:3]]  # Top 3 moins confiants
    print(f"\nâŒ Faux nÃ©gatifs (positifs prÃ©dits comme nÃ©gatifs) :")
    for i, idx in enumerate(fn_confident):
        print(f"\n{i+1}. Confiance: {1-y_pred_proba[idx]:.1%}")
        decoded = decode_review(X_test[idx])
        clean_text = decoded.replace('<START>', '').replace('<PAD>', '').strip()
        words = clean_text.split()[:25]
        print(f"   Texte: {' '.join(words)}...")

# Test de cas difficiles
print(f"\nğŸ§ª Test de cas difficiles :")

difficult_cases = [
    "This movie is not bad",  # NÃ©gation
    "I expected it to be terrible but it was actually okay",  # Contraste
    "The worst movie ever... just kidding it was great",  # Sarcasme
    "So bad it's good",  # Paradoxe
    "Could have been better",  # Nuance
]

for case in difficult_cases:
    sentiment, confidence, raw_score = predict_sentiment(case, model, word_index)
    print(f"\nğŸ“ \"{case}\"")
    print(f"   â†’ {sentiment} (confiance: {confidence:.1%})")
    print(f"   ğŸ’­ Analyse: Cette phrase contient des nuances difficiles Ã  interprÃ©ter")

print(f"\nğŸ’¡ Limites observÃ©es du modÃ¨le LSTM :")
print(f"   âœ… Forces :")
print(f"      - Bonne comprÃ©hension du contexte gÃ©nÃ©ral")
print(f"      - Capture des dÃ©pendances Ã  long terme")
print(f"      - Robuste aux variations de formulation")
print(f"   âŒ Limites :")
print(f"      - DifficultÃ© avec le sarcasme et l'ironie")
print(f"      - ProblÃ¨mes avec les nÃ©gations complexes")
print(f"      - Sensible aux expressions idiomatiques")
print(f"      - NÃ©cessite beaucoup de donnÃ©es d'entraÃ®nement")
```

## Cellule 11 (Code) - Comparaison avec Mistral AI (optionnel)

```python
# Comparaison avec une approche moderne (API Mistral)
print("ğŸ†š Comparaison avec l'API Mistral AI...")

# Note: Cette section nÃ©cessite une clÃ© API Mistral
# Remplacez 'your_api_key' par votre vraie clÃ© API

def analyze_with_mistral(text, api_key=None):
    """
    Analyse de sentiment avec l'API Mistral (simulation)
    """
    if api_key is None:
        # Simulation pour la dÃ©monstration
        print("âš ï¸  ClÃ© API manquante - Simulation activÃ©e")
        
        # Logique simplifiÃ©e pour la simulation
        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'best', 'love']
        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate', 'boring']
        
        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        if pos_count > neg_count:
            return "ğŸ˜Š POSITIF", 0.85
        elif neg_count > pos_count:
            return "ğŸ˜ NÃ‰GATIF", 0.85
        else:
            return "ğŸ˜ NEUTRE", 0.60
    else:
        # Code rÃ©el pour l'API Mistral (Ã  implÃ©menter)
        print("ğŸ”„ Appel Ã  l'API Mistral...")
        # ImplÃ©mentation rÃ©elle ici
        pass

# Tests comparatifs
comparison_sentences = [
    "This movie is absolutely fantastic",
    "I hated this boring film",
    "The movie was not bad at all",
    "This film is so bad it's good"
]

print(f"\nğŸ“Š Comparaison des approches :")
print(f"{'Phrase':<40} {'LSTM':<15} {'Mistral':<15} {'Accord'}")
print(f"{'='*40} {'='*15} {'='*15} {'='*6}")

for sentence in comparison_sentences:
    # PrÃ©diction LSTM
    lstm_sentiment, lstm_conf, _ = predict_sentiment(sentence, model, word_index)
    
    # PrÃ©diction Mistral (simulÃ©e)
    mistral_sentiment, mistral_conf = analyze_with_mistral(sentence)
    
    # Accord entre les deux
    accord = "âœ…" if lstm_sentiment.split()[1] == mistral_sentiment.split()[1] else "âŒ"
    
    print(f"{sentence[:38]:<40} {lstm_sentiment:<15} {mistral_sentiment:<15} {accord}")

print(f"\nğŸ’­ RÃ©flexions sur les diffÃ©rences :")
print(f"   - LSTM : BasÃ© sur des patterns appris des donnÃ©es d'entraÃ®nement")
print(f"   - Mistral : ModÃ¨le plus large avec comprÃ©hension contextuelle avancÃ©e")
print(f"   - Accord gÃ©nÃ©ral mais diffÃ©rences sur les cas complexes")
```

## Cellule 12 (Markdown) - Questions de rÃ©flexion et exercices

```markdown
## ğŸ¤” Questions de rÃ©flexion

AprÃ¨s avoir terminÃ© ce notebook, rÃ©flÃ©chissez aux questions suivantes :

### 1. Architecture et fonctionnement
- Comment le texte est-il transformÃ© en donnÃ©es numÃ©riques utilisables par le LSTM ?
- Pourquoi utilise-t-on des embeddings plutÃ´t que du one-hot encoding ?
- Quel est le rÃ´le de chaque porte dans une cellule LSTM ?

### 2. Preprocessing et donnÃ©es
- Pourquoi est-il nÃ©cessaire de faire du padding sur les sÃ©quences ?
- Quel impact a la longueur maximale choisie (MAX_LEN) sur les performances ?
- Comment pourrait-on amÃ©liorer le preprocessing pour de meilleurs rÃ©sultats ?

### 3. Performance et limitations
- Dans quels cas le modÃ¨le LSTM Ã©choue-t-il le plus souvent ?
- Comment pourrait-on amÃ©liorer la dÃ©tection du sarcasme et de l'ironie ?
- Quels sont les avantages/inconvÃ©nients par rapport aux approches plus rÃ©centes ?

### 4. Applications pratiques
- Dans quels contextes professionnels cette technologie serait-elle utile ?
- Comment adapter ce modÃ¨le pour analyser des avis en franÃ§ais ?
- Quelles considÃ©rations Ã©thiques faut-il prendre en compte ?

## ğŸ‹ï¸ Exercices d'approfondissement

### Exercice 1 : Modification de l'architecture
Modifiez le modÃ¨le pour inclure :
- Une couche LSTM bidirectionnelle
- Plus de couches LSTM empilÃ©es
- Une couche d'attention

### Exercice 2 : AmÃ©lioration des donnÃ©es
- Testez avec diffÃ©rentes valeurs de MAX_LEN
- Essayez d'autres techniques de preprocessing
- ImplÃ©mentez de l'augmentation de donnÃ©es pour le texte

### Exercice 3 : Ã‰valuation avancÃ©e
- Calculez des mÃ©triques plus dÃ©taillÃ©es (F1-score, prÃ©cision, rappel par classe)
- Analysez les erreurs de maniÃ¨re plus systÃ©matique
- CrÃ©ez des visualisations des performances

### Exercice 4 : Application pratique
- Adaptez le modÃ¨le pour un autre dataset (par exemple, des avis produits)
- ImplÃ©mentez une interface web simple pour tester le modÃ¨le
- Comparez avec d'autres approches (rÃ¨gles, ML classique)
```

## Cellule 13 (Markdown) - Conclusion et liens vers le projet chatbot

```markdown
## ğŸ¯ Conclusion : Vers le chatbot pÃ©dagogique

### Ce que vous avez appris

âœ… **Concepts techniques maÃ®trisÃ©s :**
- Fonctionnement des rÃ©seaux rÃ©currents et des cellules LSTM
- Preprocessing de donnÃ©es textuelles pour l'IA
- CrÃ©ation d'embeddings de mots et leur visualisation
- Ã‰valuation et analyse des performances d'un modÃ¨le NLP

âœ… **CompÃ©tences pratiques dÃ©veloppÃ©es :**
- ImplÃ©mentation complÃ¨te d'un modÃ¨le LSTM avec TensorFlow/Keras
- Debugging et optimisation d'un modÃ¨le de Deep Learning
- Analyse critique des limites et biais d'un modÃ¨le
- Comparaison d'approches diffÃ©rentes pour le mÃªme problÃ¨me

### Liens avec le projet final

ğŸš€ **Applications pour votre chatbot pÃ©dagogique :**

1. **ComprÃ©hension du contexte :** Les principes des RNN/LSTM vous aideront Ã  comprendre comment les LLM comme Mistral traitent les conversations sÃ©quentielles.

2. **Gestion de l'historique :** Votre chatbot devra maintenir le contexte d'une conversation, similaire Ã  la mÃ©moire des LSTM.

3. **QualitÃ© des rÃ©ponses :** L'analyse de sentiment peut vous aider Ã  Ã©valuer si les rÃ©ponses de votre chatbot sont appropriÃ©es.

4. **Embeddings et sÃ©mantique :** La visualisation des embeddings vous donne une intuition sur comment les modÃ¨les comprennent les relations entre concepts.

### Prochaines Ã©tapes

ğŸ“š **Pour aller plus loin :**
- Module 3 : Applications professionnelles et intÃ©gration d'APIs
- Module 4 : DÃ©veloppement de votre chatbot pÃ©dagogique
- Exploration des modÃ¨les Transformer et des LLM modernes

ğŸ’¡ **RÃ©flexion personnelle :**
Prenez quelques minutes pour noter :
- Les concepts qui vous ont le plus marquÃ©
- Les applications que vous imaginez dans votre contexte professionnel
- Les questions qui restent ouvertes pour vous

ğŸ”— **Ressources complÃ©mentaires :**
- [Understanding LSTM Networks - Colah's Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [Documentation TensorFlow sur les RNN](https://www.tensorflow.org/guide/keras/rnn)
- [Tutoriel complet sur le NLP avec TensorFlow](https://www.tensorflow.org/text)

---

**Bravo ! Vous avez terminÃ© votre exploration des rÃ©seaux rÃ©currents ! ğŸ‰**

*Passez maintenant au QCM d'Ã©valuation du Module 2 pour valider vos acquis.*
```

