# üìù QCM d'auto-√©valuation - Module 1 : Fondamentaux du Deep Learning

Ce QCM vous permettra d'√©valuer votre compr√©hension des concepts fondamentaux du Deep Learning vus durant cette premi√®re s√©ance.

## ‚úÖ Instructions
- Cochez la ou les r√©ponses correctes pour chaque question
- Certaines questions peuvent avoir plusieurs r√©ponses correctes
- Pour les questions √† choix multiples, 0,5 point est attribu√© par r√©ponse correcte (maximum 1 point par question)
- √Ä la fin du questionnaire, calculez votre score gr√¢ce au corrig√© fourni
- Dur√©e recommand√©e : 20 minutes

## üîç Partie 1 : Introduction pratique

### 1. Dans le "Hello World" du Deep Learning avec MNIST, que repr√©sentent les donn√©es d'entr√©e ?
- [ ] Des √©chantillons de texte manuscrit
- [ ] Des images de chiffres manuscrits de 0 √† 9
- [ ] Des enregistrements audio de chiffres prononc√©s
- [ ] Des coordonn√©es de points repr√©sentant des chiffres

### 2. Lors de la normalisation des donn√©es d'image MNIST, pourquoi divise-t-on les valeurs des pixels par 255 ?
- [ ] Pour compresser les images et √©conomiser de la m√©moire
- [ ] Pour ramener toutes les valeurs entre 0 et 1
- [ ] Pour augmenter la vitesse de traitement
- [ ] Pour convertir les images en noir et blanc

### 3. Parmi ces applications, laquelle n'est PAS un exemple typique de Deep Learning pr√©sent√© dans l'introduction pratique ?
- [ ] GitHub Copilot pour la compl√©tion de code
- [ ] Reconnaissance d'objets en temps r√©el 
- [ ] G√©n√©ration de texte contextuel
- [ ] Analyse statistique de donn√©es tabulaires

### 4. Lors de l'exp√©rimentation avec le mod√®le MNIST, quel param√®tre a le plus d'influence sur le temps d'entra√Ænement ?
- [ ] Le nombre d'√©poques
- [ ] La taille du batch
- [ ] Le type de fonction d'activation
- [ ] Le nombre de classes de sortie

### 5. Quels sont les avantages observ√©s du Deep Learning dans votre premi√®re exp√©rience pratique ? (plusieurs r√©ponses possibles)
- [ ] Capacit√© √† traiter directement des images brutes
- [ ] Pas besoin de pr√©traitement des donn√©es
- [ ] Apprentissage automatique des caract√©ristiques importantes
- [ ] Reconnaissance robuste malgr√© des variations dans les entr√©es
- [ ] Facilit√© d'impl√©mentation et d'entra√Ænement

## üß© Partie 2 : Concepts fondamentaux

### 6. Quelle est la principale diff√©rence entre le Machine Learning classique et le Deep Learning concernant les caract√©ristiques (features) ?
- [ ] Le Machine Learning classique fonctionne avec moins de donn√©es
- [ ] Le Deep Learning extrait automatiquement les caract√©ristiques pertinentes
- [ ] Le Machine Learning classique ne n√©cessite pas de phase d'entra√Ænement
- [ ] Le Deep Learning demande moins de puissance de calcul

### 7. Quels sont les composants fondamentaux d'un r√©seau de neurones ? (plusieurs r√©ponses possibles)
- [ ] Neurones
- [ ] Poids et connexions
- [ ] Fonctions d'activation
- [ ] Instructions conditionnelles
- [ ] Biais

### 8. Dans un r√©seau de neurones, qu'est-ce qu'une "couche cach√©e" ?
- [ ] Une couche qui n'est pas visible dans le code
- [ ] Une couche situ√©e entre la couche d'entr√©e et la couche de sortie
- [ ] Une couche qui ne s'active que dans certaines conditions
- [ ] Une couche utilis√©e uniquement pendant la phase de test

### 9. En observant le sch√©ma d'un neurone artificiel, quelles op√©rations math√©matiques sont appliqu√©es dans l'ordre correct ?
- [ ] Multiplication ‚Üí Addition ‚Üí Fonction d'activation
- [ ] Addition ‚Üí Multiplication ‚Üí Fonction d'activation
- [ ] Fonction d'activation ‚Üí Multiplication ‚Üí Addition
- [ ] Multiplication ‚Üí Fonction d'activation ‚Üí Addition

### 10. Lors de la comparaison entre Machine Learning classique et Deep Learning sur des donn√©es bruit√©es, qu'avez-vous observ√© ?
- [ ] Les deux approches ont des performances similaires
- [ ] Le Machine Learning classique est plus robuste au bruit
- [ ] Le Deep Learning maintient g√©n√©ralement de meilleures performances
- [ ] Les deux approches √©chouent compl√®tement avec des donn√©es bruit√©es

## üõ†Ô∏è Partie 3 : Mini-projet individuel

### 11. Dans le mini-projet, quelle modification a g√©n√©ralement le plus d'impact positif sur les performances du mod√®le CNN ?
- [ ] Ajouter une couche de convolution suppl√©mentaire
- [ ] Augmenter simplement le nombre de neurones dans les couches existantes
- [ ] Changer l'optimiseur d'Adam √† SGD
- [ ] R√©duire le nombre d'√©poques d'entra√Ænement

### 12. Quel est l'effet principal de l'ajout d'une couche de Dropout dans un mod√®le de Deep Learning ?
- [ ] Acc√©l√©ration de l'entra√Ænement
- [ ] R√©duction du surapprentissage (overfitting)
- [ ] Am√©lioration des performances sur les donn√©es complexes
- [ ] Simplification de l'architecture du r√©seau

### 13. Analysez ce graphique d'entra√Ænement. Quelle affirmation est correcte ?

```
Pr√©cision
^
|
|      ****     *******
|    **               ******
|   *                        ******
|  *
| *
|*
+---------------------------------> √âpoques
  ‚Äî Entra√Ænement   .... Validation
```

- [ ] Le mod√®le n'apprend pas correctement
- [ ] Le mod√®le souffre de surapprentissage
- [ ] Le mod√®le souffre de sous-apprentissage
- [ ] Le mod√®le g√©n√©ralise parfaitement

### 14. Lors du test du mod√®le sur des donn√©es bruit√©es, quelle modification tend √† am√©liorer le plus la robustesse ?
- [ ] Augmentation du nombre d'√©poques
- [ ] Ajout de couches de Dropout
- [ ] R√©duction du nombre de neurones
- [ ] Changement de la fonction d'activation

### 15. Quelle relation d√©crit le mieux le lien entre les trois phases du Module 1 ?
- [ ] Chaque phase est ind√©pendante et peut √™tre √©tudi√©e s√©par√©ment
- [ ] La Phase 1 fournit l'exp√©rience pratique, la Phase 2 explique les concepts, et la Phase 3 applique ces connaissances
- [ ] Les phases doivent obligatoirement √™tre suivies dans l'ordre pour comprendre le Deep Learning
- [ ] Les phases repr√©sentent trois approches alternatives pour apprendre le Deep Learning

## Auto-√©valuation

Une fois le QCM compl√©t√©, v√©rifiez vos r√©ponses avec le corrig√© ci-dessous et calculez votre score.

### Corrig√© avec explications

1. **b - Des images de chiffres manuscrits de 0 √† 9**  
   *Le dataset MNIST contient 70 000 images en niveaux de gris de chiffres manuscrits, format standard pour d√©buter en Deep Learning.*

2. **b - Pour ramener toutes les valeurs entre 0 et 1**  
   *La normalisation des valeurs de pixels (qui sont initialement entre 0 et 255) permet de stabiliser l'entra√Ænement et d'acc√©l√©rer la convergence du mod√®le.*

3. **d - Analyse statistique de donn√©es tabulaires**  
   *C'est typiquement un cas o√π le Machine Learning classique est plus appropri√© que le Deep Learning. Les autres options sont des applications typiques de Deep Learning pr√©sent√©es dans l'introduction.*

4. **a - Le nombre d'√©poques**  
   *Une √©poque repr√©sente un passage complet sur toutes les donn√©es d'entra√Ænement. Augmenter le nombre d'√©poques multiplie proportionnellement le temps d'entra√Ænement.*

5. **a, c, d - Capacit√© √† traiter directement des images brutes, Apprentissage automatique des caract√©ristiques importantes, Reconnaissance robuste malgr√© des variations dans les entr√©es**  
   *Le Deep Learning requiert g√©n√©ralement un pr√©traitement (normalisation), donc b est incorrect. Il n'est pas n√©cessairement plus facile √† impl√©menter que le ML classique, donc e est incorrect.*

6. **b - Le Deep Learning extrait automatiquement les caract√©ristiques pertinentes**  
   *C'est la diff√©rence fondamentale : le ML classique n√©cessite une extraction manuelle des caract√©ristiques alors que le DL les apprend automatiquement √† partir des donn√©es brutes.*

7. **a, b, c, e - Neurones, Poids et connexions, Fonctions d'activation, Biais**  
   *Les instructions conditionnelles ne font pas partie de la structure standard d'un r√©seau de neurones.*

8. **b - Une couche situ√©e entre la couche d'entr√©e et la couche de sortie**  
   *Les couches cach√©es sont responsables de l'extraction progressive des caract√©ristiques et sont situ√©es entre l'entr√©e et la sortie du r√©seau.*

9. **a - Multiplication ‚Üí Addition ‚Üí Fonction d'activation**  
   *Dans un neurone artificiel, on multiplie d'abord les entr√©es par les poids, puis on additionne ces produits avec le biais, et enfin on applique la fonction d'activation.*

10. **c - Le Deep Learning maintient g√©n√©ralement de meilleures performances**  
    *Gr√¢ce √† sa capacit√© √† extraire des caract√©ristiques hi√©rarchiques complexes, le Deep Learning est souvent plus robuste aux variations et au bruit dans les donn√©es.*

11. **a - Ajouter une couche de convolution suppl√©mentaire**  
    *Cette modification permet au r√©seau d'extraire des caract√©ristiques plus complexes et plus abstraites, am√©liorant g√©n√©ralement les performances sur MNIST.*

12. **b - R√©duction du surapprentissage (overfitting)**  
    *Le Dropout d√©sactive al√©atoirement des neurones pendant l'entra√Ænement, ce qui emp√™che le r√©seau de trop s'adapter aux donn√©es d'entra√Ænement et am√©liore la g√©n√©ralisation.*

13. **b - Le mod√®le souffre de surapprentissage**  
    *Le graphique montre que la pr√©cision sur les donn√©es d'entra√Ænement continue d'augmenter alors que celle sur les donn√©es de validation commence √† diminuer, signe classique de surapprentissage.*

14. **b - Ajout de couches de Dropout**  
    *Le Dropout am√©liore la robustesse du mod√®le en le for√ßant √† ne pas d√©pendre excessivement de certains neurones, ce qui le rend plus performant sur des donn√©es bruit√©es ou l√©g√®rement diff√©rentes.*

15. **b - La Phase 1 fournit l'exp√©rience pratique, la Phase 2 explique les concepts, et la Phase 3 applique ces connaissances**  
    *Cette structure suit l'approche p√©dagogique du module : pratique d'abord, conceptualisation ensuite, et application finale dans un projet.*

### Calcul de votre score
- Questions √† choix unique (1-4, 6, 8-15) : 1 point par r√©ponse correcte
- Questions √† choix multiples (5, 7) : 0,5 point par r√©ponse correcte et -0,25 par r√©ponse incorrecte (minimum 0, maximum 1 point par question)

**Total des points possibles : 15**

### Interpr√©tation
- **12-15 points** : Excellente ma√Ætrise des concepts fondamentaux du Deep Learning
- **9-11 points** : Bonne compr√©hension, quelques points √† clarifier
- **6-8 points** : Compr√©hension de base, r√©vision n√©cessaire de certains concepts
- **0-5 points** : R√©vision approfondie recommand√©e avant de poursuivre

## Pour approfondir
Si vous avez obtenu moins de 12 points, nous vous recommandons de revoir les concepts sur lesquels vous avez fait des erreurs. Consultez les ressources suivantes :

  - Le notebook ["Hello World du Deep Learning"](../module1/ressources/hello-world-dl.md) (Phase 1)
  - La section ["Concepts fondamentaux"](../module1/concepts-fondamentaux.md) du cours (Phase 2)
  - La ["fiche d'observations du mini-projet d'am√©lioration"](../module1/ressources/Partie1-Phase3-fiche-observations.md) (Phase 3)
  - Le [glossaire des termes du Deep Learning](../module1/ressources/glossaire-dl.md)