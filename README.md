# üìö Chatbot IA avec Base Documentaire

Un chatbot intelligent utilisant RAG (Retrieval-Augmented Generation) pour analyser et r√©pondre aux questions bas√©es sur vos documents.

## ‚ú® Fonctionnalit√©s

### üîç Analyse de Documents
- **Formats support√©s** : TXT, MD, PDF, Python, JavaScript, HTML, CSS, JSON, XML
- **Sources multiples** : Repository Git, upload de fichiers, dossiers locaux
- **Indexation intelligente** : D√©coupage automatique et embeddings vectoriels

### üí¨ Conversation Avanc√©e
- **Historique contextuel** : Maintien du contexte sur plusieurs √©changes
- **Sources trac√©es** : R√©f√©rences pr√©cises aux documents utilis√©s
- **Score de confiance** : √âvaluation de la fiabilit√© des r√©ponses

### üõ†Ô∏è Interface Compl√®te
- **Interface Streamlit moderne** : Design responsive et intuitif
- **Recherche de documents** : Exploration directe de la base vectorielle
- **Export de conversations** : Sauvegarde en format Markdown
- **Statistiques d√©taill√©es** : M√©triques de performance et d'usage

### üîß Configuration Flexible
- **Multi-providers** : Support OpenAI et Mistral AI
- **Param√®tres ajustables** : Taille des chunks, seuils de similarit√©
- **Variables d'environnement** : Configuration s√©curis√©e

## üöÄ Installation

### Pr√©requis
- Python 3.11+
- Git
- Cl√© API OpenAI ou Mistral AI

### √âtapes d'installation

1. **Cloner le repository**
```bash
git clone https://github.com/votre-username/chatbot-ia.git
cd chatbot-ia
```

2. **Installer les d√©pendances**
```bash
pip install -r requirements.txt
```

3. **Configuration**
```bash
cp .env.example .env
# √âditer le fichier .env avec vos cl√©s API
```

4. **Lancer l'application**
```bash
streamlit run app/main.py
```

## ‚öôÔ∏è Configuration

### Variables d'environnement principales

| Variable | Description | Valeur par d√©faut |
|----------|-------------|-------------------|
| `PROVIDER` | Provider LLM (openai/mistral) | `openai` |
| `OPENAI_API_KEY` | Cl√© API OpenAI | Obligatoire si provider=openai |
| `MISTRAL_API_KEY` | Cl√© API Mistral | Obligatoire si provider=mistral |
| `MODEL_NAME` | Nom du mod√®le | `gpt-3.5-turbo` |
| `CHUNK_SIZE` | Taille des chunks | `1000` |
| `MAX_RESULTS` | Nombre max de r√©sultats | `4` |

### Configuration avanc√©e

```bash
# Embeddings
EMBEDDING_MODEL=text-embedding-ada-002

# D√©coupage de documents
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Recherche vectorielle
MAX_RESULTS=4
SIMILARITY_THRESHOLD=0.7
```

## üìñ Utilisation

### 1. Indexation de documents

#### Via Repository Git
1. Dans la sidebar, onglet "Repository"
2. Entrer l'URL du repository Git
3. Cliquer sur "Cloner et indexer"

#### Via Upload de fichiers
1. Dans la sidebar, onglet "Upload"
2. S√©lectionner les fichiers √† analyser
3. Cliquer sur "Uploader et indexer"

### 2. Poser des questions

- Utiliser la zone de chat principale
- Activer l'historique contextuel si d√©sir√©
- Explorer les questions sugg√©r√©es

### 3. Analyser les r√©sultats

- **Sources** : Consulter les documents utilis√©s
- **Confiance** : √âvaluer la fiabilit√©
- **Recherche** : Explorer la base documentaire

### 4. Export et sauvegarde

- Exporter les conversations en Markdown
- Consulter les statistiques de session
- Effacer l'historique si n√©cessaire

## üèóÔ∏è Architecture

```
app/
‚îú‚îÄ‚îÄ __init__.py          # Package principal
‚îú‚îÄ‚îÄ config.py            # Configuration et validation
‚îú‚îÄ‚îÄ ingest.py            # Ingestion et indexation des documents
‚îú‚îÄ‚îÄ qa_chain.py          # Cha√Æne QA et logique de conversation
‚îî‚îÄ‚îÄ main.py              # Interface Streamlit

data/                    # Documents sources (auto-g√©n√©r√©)
vectorstore/            # Base vectorielle FAISS (auto-g√©n√©r√©)
.devcontainer/          # Configuration pour GitHub Codespaces
```

### Flux de donn√©es

1. **Ingestion** : Documents ‚Üí Chunks ‚Üí Embeddings ‚Üí FAISS
2. **Requ√™te** : Question ‚Üí Recherche vectorielle ‚Üí Contexte
3. **G√©n√©ration** : LLM + Contexte ‚Üí R√©ponse + Sources

## üõ°Ô∏è S√©curit√© et Bonnes Pratiques

### Gestion des cl√©s API
- Utiliser des variables d'environnement
- Ne jamais commiter les fichiers `.env`
- Rotation r√©guli√®re des cl√©s

### Optimisation des co√ªts
- Ajuster `CHUNK_SIZE` selon le budget
- Limiter `MAX_RESULTS` pour r√©duire les tokens
- Utiliser des mod√®les moins co√ªteux pour les tests

### Performance
- Indexer uniquement les documents n√©cessaires
- Nettoyer r√©guli√®rement le vectorstore
- Monitorer les m√©triques de confiance

## üîß D√©veloppement

### Structure de d√©veloppement
```bash
# Tests
pytest tests/

# Formatage du code
black app/

# Linting
flake8 app/
```

### Ajout de nouvelles fonctionnalit√©s

1. **Nouveaux formats de documents** : √âtendre `DocumentIngestor`
2. **Nouveaux providers LLM** : Modifier `AdvancedQAChain`
3. **Interface utilisateur** : Personnaliser `main.py`

### Variables de session Streamlit

| Variable | Usage |
|----------|-------|
| `st.session_state.qa_chain` | Instance principale QA |
| `st.session_state.messages` | Historique de chat |

## üìä M√©triques et Monitoring

### M√©triques automatiques
- Nombre de documents index√©s
- Confiance moyenne des r√©ponses
- Nombre d'interactions par session

### M√©triques personnalis√©es
- Temps de r√©ponse
- Utilisation des tokens
- Satisfaction utilisateur

## ü§ù Contribution

1. Fork le repository
2. Cr√©er une branche pour votre fonctionnalit√©
3. Ajouter des tests si n√©cessaire
4. Soumettre une Pull Request

## üìù Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üÜò Support

### FAQ

**Q: Comment ajouter support pour d'autres formats ?**
R: √âtendre la classe `DocumentIngestor` avec de nouveaux loaders LangChain.

**Q: Peut-on utiliser d'autres bases vectorielles ?**
R: Oui, remplacer FAISS par Chroma, Pinecone, etc. dans `qa_chain.py`.

**Q: Comment optimiser la qualit√© des r√©ponses ?**
R: Ajuster les prompts, la taille des chunks, et le seuil de similarit√©.

### Probl√®mes courants

- **Erreur de cl√© API** : V√©rifier le fichier `.env`
- **Documents non trouv√©s** : R√©indexer avec le bon format
- **R√©ponses de faible qualit√©** : Ajuster les param√®tres de recherche

---

D√©velopp√© pour G.G - Projet d'intelligence artificielle appliqu√©e